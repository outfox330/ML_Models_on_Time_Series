{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple example to illustrate the training of RNN in Keras\n",
    "- RNN is designed to retain context of past to make predictions for the future.\n",
    "- Here, we will first use a special kind of RNN called LSTM. \n",
    "- Credits based on github repo: https://github.com/WillKoehrsen/recurrent-neural-networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category = UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import get_data, generate_output, guess_human, seed_sequence, get_embeddings, find_closest, format_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch the data\n",
    "- 3000+ patents total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" A \"\"Barometer\"\" Neuron enhances stability in...</td>\n",
       "      <td>1996-07-09</td>\n",
       "      <td>5535303</td>\n",
       "      <td>\"\"\"Barometer\"\" neuron for a neural network\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\" This invention is a novel high-speed neural ...</td>\n",
       "      <td>1993-10-19</td>\n",
       "      <td>5255349</td>\n",
       "      <td>\"Electronic neural network for solving \"\"trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An optical information processor for use as a ...</td>\n",
       "      <td>1995-01-17</td>\n",
       "      <td>5383042</td>\n",
       "      <td>3 layer liquid crystal neural network with out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A method and system for intelligent control of...</td>\n",
       "      <td>2001-01-02</td>\n",
       "      <td>6169981</td>\n",
       "      <td>3-brain architecture for an intelligent decisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A method and system for intelligent control of...</td>\n",
       "      <td>2003-06-17</td>\n",
       "      <td>6581048</td>\n",
       "      <td>3-brain architecture for an intelligent decisi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     patent_abstract patent_date  \\\n",
       "0  \" A \"\"Barometer\"\" Neuron enhances stability in...  1996-07-09   \n",
       "1  \" This invention is a novel high-speed neural ...  1993-10-19   \n",
       "2  An optical information processor for use as a ...  1995-01-17   \n",
       "3  A method and system for intelligent control of...  2001-01-02   \n",
       "4  A method and system for intelligent control of...  2003-06-17   \n",
       "\n",
       "  patent_number                                       patent_title  \n",
       "0       5535303        \"\"\"Barometer\"\" neuron for a neural network\"  \n",
       "1       5255349  \"Electronic neural network for solving \"\"trave...  \n",
       "2       5383042  3 layer liquid crystal neural network with out...  \n",
       "3       6169981  3-brain architecture for an intelligent decisi...  \n",
       "4       6581048  3-brain architecture for an intelligent decisi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/neural_network_patent_query.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16192 unique words.\n",
      "There are 318563 sequences.\n"
     ]
    }
   ],
   "source": [
    "training_dict, word_idx, idx_word, sequences = get_data('data/neural_network_patent_query.csv', training_len = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sequences of text are represented as integers\n",
    "- word_idx maps words to integers\n",
    "- idx_word maps integers to words\n",
    "- Features are integer sequences of length 50\n",
    "- Label is next word in sequence\n",
    "- Labels are one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  117     7   141   277     4    18    81   110    10   219    29     1\n",
      "    952  2453    19     5     6     1   117    10   182  2166    21     1\n",
      "     81   178     4    13   117   894    14  6163     7   302     1     9\n",
      "      8    29    33    23    74   428     7   692     1    81   183     4\n",
      "     13   117]\n",
      " [    6    41     2    87     3  1340    79     7     1   409   543    22\n",
      "    484     6     2  2113   728    24     1   178     3     1  1820    55\n",
      "     14 13942  7240   244     5    14 13943  7240   244     5     2  2113\n",
      "   7240   244     5     2    38  9292   244     2    49  9292   244    14\n",
      "     22 13944]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(training_dict['X_train'][:2])\n",
    "print(training_dict['y_train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: user to provide samples . A recognition operation is performed on the user's handwritten input , and the user is not satisfied with the recognition result . The user selects an option to train the neural network on one or more characters to improve the recognition results . The user\n",
      "\n",
      "Label: is\n",
      "\n",
      "Features: and includes a number of amplifiers corresponding to the N bit output sum and a carry generation from the result of the adding process an augend input-synapse group , an addend input-synapse group , a carry input-synapse group , a first bias-synapse group a second bias-synapse group an output feedback-synapse\n",
      "\n",
      "Label: group\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sequence in enumerate(training_dict['X_train'][:2]):\n",
    "    text = []\n",
    "    for idx in sequence:\n",
    "        text.append(idx_word[idx])\n",
    "        \n",
    "    print('Features: ' + ' '.join(text) + '\\n')\n",
    "    print('Label: ' + idx_word[np.argmax(training_dict['y_train'][i])] + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Make RNN (LSTM)\n",
    "- Embedding dimension = 100\n",
    "- 64 LSTM cells in one layer\n",
    "- Dropout and recurrent dropout for regularization\n",
    "- Fully connected layer with 64 units on top of LSTM\n",
    "- 'relu' activation\n",
    "- Drop out for regularization\n",
    "- Output layer produces prediction for each word\n",
    "- 'softmax' activation\n",
    "- Adam optimizer with defaults\n",
    "- Categorical cross entropy loss\n",
    "- Monitor accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         1619200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16192)             1052480   \n",
      "=================================================================\n",
      "Total params: 2,718,080\n",
      "Trainable params: 2,718,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "# Embedding layer\n",
    "model.add(Embedding(input_dim=len(word_idx) + 1,output_dim=100,weights=None,trainable=True))\n",
    "\n",
    "# Recurrent layer\n",
    "model.add(LSTM(64, return_sequences=False, dropout=0.1,recurrent_dropout=0.1))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Dropout for regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(len(word_idx) + 1, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Pre-Trained Model\n",
    "Rather than waiting several hours to train the model, we can load in a model trained for 150 epochs. We'll demonstrate how to train this model for another 5 epochs which shouldn't take too long depending on your hardware.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sandeep/miniconda3/envs/mango/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/sandeep/miniconda3/envs/mango/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 222994 samples, validate on 95569 samples\n",
      "Epoch 1/1\n",
      "222994/222994 [==============================] - 166s 743us/step - loss: 3.7614 - accuracy: 0.2943 - val_loss: 5.1229 - val_accuracy: 0.2681\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load in model and demonstrate training\n",
    "model = load_model('models/train-embeddings-rnn.h5')\n",
    "#model.load_weights('models/train-embeddings-rnn.h5')\n",
    "\n",
    "h = model.fit(training_dict['X_train'], training_dict['y_train'], epochs = 1, batch_size = 2048, \n",
    "          validation_data = (training_dict['X_valid'], training_dict['y_valid']), \n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: Log Loss and Accuracy on training data\n",
      "222994/222994 [==============================] - 79s 356us/step\n",
      "\n",
      "Model Performance: Log Loss and Accuracy on validation data\n",
      "95569/95569 [==============================] - 34s 354us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.122893927639151, 0.2681204080581665]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model Performance: Log Loss and Accuracy on training data')\n",
    "model.evaluate(training_dict['X_train'], training_dict['y_train'], batch_size = 2048)\n",
    "\n",
    "print('\\nModel Performance: Log Loss and Accuracy on validation data')\n",
    "model.evaluate(training_dict['X_valid'], training_dict['y_valid'], batch_size = 2048)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here you can input your own starting sequence for the network. The network will produce num_words of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: black;\"><p><center>Input Seed <span style=\"color: red\">Network Output</center></p></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\"> <p>This patent provides a basis for using a LSTM neural network to <span style=\"color: red\">a neural result indicative that 101 and the data requests may be used to determine if a plurality of neural</p></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'This patent provides a basis for using a LSTM neural network to '\n",
    "HTML(seed_sequence(model, s, word_idx, idx_word, diversity = 0.75, num_words = 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the seed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'patent', 'provides', 'a', 'basis', 'for', 'using', 'a', 'neural', 'network', 'to']\n"
     ]
    }
   ],
   "source": [
    "s = 'This patent provides a basis for using a neural network to '\n",
    "diversity = 0.75\n",
    "num_words = 20\n",
    "\n",
    "start = format_sequence(s).split()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_spaces(s):\n",
    "    \"\"\"Remove spaces around punctuation\"\"\"\n",
    "    s = re.sub(r'\\s+([.,;?])', r'\\1', s)\n",
    "    return s\n",
    "\n",
    "def addContent(old_html, raw_html):\n",
    "    old_html += raw_html\n",
    "    return old_html\n",
    "\n",
    "def header(text, color = 'black', gen_text = None):\n",
    "    if gen_text:\n",
    "        raw_html = f'<h1 style=\"color: {color};\"><p><center>' + str(\n",
    "        text) + '<span style=\"color: red\">' + str(gen_text) + '</center></p></h1>'\n",
    "    else:\n",
    "        raw_html = f'<h1 style=\"color: {color};\"><center>' + str(\n",
    "            text) + '</center></h1>'\n",
    "    return raw_html\n",
    "\n",
    "\n",
    "def box(text, gen_text=None):\n",
    "    if gen_text:\n",
    "        raw_html = '<div style=\"border:1px inset black;padding:1em;font-size: 20px;\"> <p>' + str(\n",
    "            text) +'<span style=\"color: red\">' + str(gen_text) + '</p></div>'\n",
    "\n",
    "    else:\n",
    "        raw_html = '<div style=\"border:1px inset black;padding:1em;font-size: 20px;\">' + str(\n",
    "            text) + '</div>'\n",
    "    return raw_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = []\n",
    "s = start[:]\n",
    "\n",
    "# Generate output\n",
    "for _ in range(num_words):\n",
    "    # Conver to arrary of words as input\n",
    "    x = np.array([word_idx.get(word, 0) for word in s]).reshape((1, -1))\n",
    "    #print('x is:', x.shape)\n",
    "    \n",
    "    # Make predictions: Next word propabilities\n",
    "    preds = model.predict(x)[0].astype(float)\n",
    "    #print('preds is:', preds.shape)\n",
    "    \n",
    "    # Diversify\n",
    "    preds = np.log(preds) / diversity\n",
    "    exp_preds = np.exp(preds)\n",
    "    # Softmax\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    # Pick next index\n",
    "    next_idx = np.argmax(np.random.multinomial(1, preds, size = 1))\n",
    "    s.append(idx_word[next_idx])\n",
    "    gen.append(idx_word[next_idx])\n",
    "\n",
    "# Formatting in html\n",
    "start = remove_spaces(' '.join(start)) + ' '\n",
    "gen = remove_spaces(' '.join(gen)) \n",
    "html = ''\n",
    "html = addContent(html, header('Input Seed ', color = 'black', gen_text = 'Network Output'))\n",
    "html = addContent(html, box(start, gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1 style=\"color: black;\"><p><center>Input Seed <span style=\"color: red\">Network Output</center></p></h1><div style=\"border:1px inset black;padding:1em;font-size: 20px;\"> <p>This patent provides a basis for using a neural network to <span style=\"color: red\">nonlinear modeling neural system for changing a reduction of standard. A neural network has an output of the network</p></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
