{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the TCN's for human activity classification with other Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: We use a much simpler workflow: We don't do careful validation split, and don't repeat experiments to save the training time. This is just to illustrate a wider picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. First let us train a simple CNN to do the job for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset: https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones\n",
    "- Video of process: https://www.youtube.com/watch?v=XOEN9W05_4A\n",
    "- Observations at 50 Hz (i.e. 50 points per second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Released dataset details\n",
    "- Pre-processing accelerometer and gyroscope using noise filters.\n",
    "- Splitting data into fixed windows of 2.56 seconds (128 data points) with 50% overlap.\n",
    "- Segregation of accelerometer data into gravity and motion components.\n",
    "- The dataset was split into train (70%) and test (30%) sets based on data for subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Convolutional Neural Network\n",
    "- The model learns to extract features from intertial sensors and maps them to different activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "        \n",
    "    loaded = dstack(loaded)\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us play with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cnn(n_timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=16, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 1, 25, 32\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "model = get_model_cnn(n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 126, 16)           448       \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 124, 16)           784       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 124, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 62, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 992)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                63552     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 65,174\n",
      "Trainable params: 65,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7352/7352 [==============================] - 2s 210us/step - loss: 0.5706 - accuracy: 0.7741\n",
      "Epoch 2/25\n",
      "7352/7352 [==============================] - 1s 182us/step - loss: 0.2056 - accuracy: 0.9217\n",
      "Epoch 3/25\n",
      "7352/7352 [==============================] - 1s 183us/step - loss: 0.1456 - accuracy: 0.9421\n",
      "Epoch 4/25\n",
      "7352/7352 [==============================] - 1s 184us/step - loss: 0.1301 - accuracy: 0.9471\n",
      "Epoch 5/25\n",
      "7352/7352 [==============================] - 1s 179us/step - loss: 0.1137 - accuracy: 0.9535\n",
      "Epoch 6/25\n",
      "7352/7352 [==============================] - 1s 178us/step - loss: 0.1089 - accuracy: 0.9518\n",
      "Epoch 7/25\n",
      "7352/7352 [==============================] - 1s 177us/step - loss: 0.1054 - accuracy: 0.9546\n",
      "Epoch 8/25\n",
      "7352/7352 [==============================] - 1s 177us/step - loss: 0.1084 - accuracy: 0.9529\n",
      "Epoch 9/25\n",
      "7352/7352 [==============================] - 1s 180us/step - loss: 0.1092 - accuracy: 0.9523\n",
      "Epoch 10/25\n",
      "7352/7352 [==============================] - 1s 186us/step - loss: 0.0997 - accuracy: 0.9551\n",
      "Epoch 11/25\n",
      "7352/7352 [==============================] - 1s 177us/step - loss: 0.0963 - accuracy: 0.9576\n",
      "Epoch 12/25\n",
      "7352/7352 [==============================] - 1s 177us/step - loss: 0.0952 - accuracy: 0.9567\n",
      "Epoch 13/25\n",
      "7352/7352 [==============================] - 1s 178us/step - loss: 0.0910 - accuracy: 0.9612\n",
      "Epoch 14/25\n",
      "7352/7352 [==============================] - 1s 178us/step - loss: 0.0922 - accuracy: 0.9581\n",
      "Epoch 15/25\n",
      "7352/7352 [==============================] - 1s 172us/step - loss: 0.0899 - accuracy: 0.9607\n",
      "Epoch 16/25\n",
      "7352/7352 [==============================] - 1s 171us/step - loss: 0.0917 - accuracy: 0.9589\n",
      "Epoch 17/25\n",
      "7352/7352 [==============================] - 1s 183us/step - loss: 0.0843 - accuracy: 0.9615\n",
      "Epoch 18/25\n",
      "7352/7352 [==============================] - 1s 174us/step - loss: 0.0727 - accuracy: 0.9649\n",
      "Epoch 19/25\n",
      "7352/7352 [==============================] - 1s 172us/step - loss: 0.0722 - accuracy: 0.9655\n",
      "Epoch 20/25\n",
      "7352/7352 [==============================] - 1s 171us/step - loss: 0.0697 - accuracy: 0.9686\n",
      "Epoch 21/25\n",
      "7352/7352 [==============================] - 1s 171us/step - loss: 0.0641 - accuracy: 0.9701\n",
      "Epoch 22/25\n",
      "7352/7352 [==============================] - 1s 182us/step - loss: 0.0709 - accuracy: 0.9686\n",
      "Epoch 23/25\n",
      "7352/7352 [==============================] - 1s 176us/step - loss: 0.0635 - accuracy: 0.9713\n",
      "Epoch 24/25\n",
      "7352/7352 [==============================] - 1s 176us/step - loss: 0.0659 - accuracy: 0.9697\n",
      "Epoch 25/25\n",
      "7352/7352 [==============================] - 1s 174us/step - loss: 0.0637 - accuracy: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe3db907dd8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model is: 0.8802171945571899\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy of model is:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Let us train a  simple TCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPooling1D, Flatten\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tcn(n_timesteps, n_features, nb_filters, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(TCN(input_shape=(n_timesteps, n_features),\n",
    "        nb_filters=nb_filters,\n",
    "        kernel_size=3,\n",
    "        nb_stacks=1,\n",
    "        use_skip_connections=False,\n",
    "        use_batch_norm=False,\n",
    "        use_weight_norm=False,\n",
    "        use_layer_norm=False))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose, epochs, batch_size = 1, 25, 32\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "model = get_model_tcn(n_timesteps, n_features, 16, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "tcn_12 (TCN)                 (None, 16)                9232      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 10,710\n",
      "Trainable params: 10,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7352/7352 [==============================] - 6s 752us/sample - loss: 0.2066 - acc: 0.9195\n",
      "Epoch 2/25\n",
      "7352/7352 [==============================] - 5s 742us/sample - loss: 0.1529 - acc: 0.9353\n",
      "Epoch 3/25\n",
      "7352/7352 [==============================] - 6s 752us/sample - loss: 0.1301 - acc: 0.9479\n",
      "Epoch 4/25\n",
      "7352/7352 [==============================] - 6s 753us/sample - loss: 0.1314 - acc: 0.9460\n",
      "Epoch 5/25\n",
      "7352/7352 [==============================] - 5s 716us/sample - loss: 0.1213 - acc: 0.9470\n",
      "Epoch 6/25\n",
      "7352/7352 [==============================] - 5s 722us/sample - loss: 0.1126 - acc: 0.9520\n",
      "Epoch 7/25\n",
      "7352/7352 [==============================] - 6s 773us/sample - loss: 0.1160 - acc: 0.9472\n",
      "Epoch 8/25\n",
      "7352/7352 [==============================] - 6s 799us/sample - loss: 0.1130 - acc: 0.9502\n",
      "Epoch 9/25\n",
      "7352/7352 [==============================] - 5s 731us/sample - loss: 0.1193 - acc: 0.9490\n",
      "Epoch 10/25\n",
      "7352/7352 [==============================] - 5s 722us/sample - loss: 0.1020 - acc: 0.9532\n",
      "Epoch 11/25\n",
      "7352/7352 [==============================] - 5s 735us/sample - loss: 0.1347 - acc: 0.9448\n",
      "Epoch 12/25\n",
      "7352/7352 [==============================] - 6s 796us/sample - loss: 0.1012 - acc: 0.9540\n",
      "Epoch 13/25\n",
      "7352/7352 [==============================] - 6s 772us/sample - loss: 0.0953 - acc: 0.9542\n",
      "Epoch 14/25\n",
      "7352/7352 [==============================] - 6s 794us/sample - loss: 0.1046 - acc: 0.9532\n",
      "Epoch 15/25\n",
      "7352/7352 [==============================] - 6s 780us/sample - loss: 0.0926 - acc: 0.9565\n",
      "Epoch 16/25\n",
      "7352/7352 [==============================] - 5s 747us/sample - loss: 0.1393 - acc: 0.9440\n",
      "Epoch 17/25\n",
      "7352/7352 [==============================] - 6s 765us/sample - loss: 0.1000 - acc: 0.9562\n",
      "Epoch 18/25\n",
      "7352/7352 [==============================] - 6s 811us/sample - loss: 0.0933 - acc: 0.9561\n",
      "Epoch 19/25\n",
      "7352/7352 [==============================] - 7s 963us/sample - loss: 0.0932 - acc: 0.9570\n",
      "Epoch 20/25\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.1005 - acc: 0.9555\n",
      "Epoch 21/25\n",
      "7352/7352 [==============================] - 10s 1ms/sample - loss: 0.0890 - acc: 0.9604\n",
      "Epoch 22/25\n",
      "7352/7352 [==============================] - 10s 1ms/sample - loss: 0.0924 - acc: 0.9569\n",
      "Epoch 23/25\n",
      "7352/7352 [==============================] - 11s 2ms/sample - loss: 0.0831 - acc: 0.9611\n",
      "Epoch 24/25\n",
      "7352/7352 [==============================] - 12s 2ms/sample - loss: 0.0778 - acc: 0.9630\n",
      "Epoch 25/25\n",
      "7352/7352 [==============================] - 13s 2ms/sample - loss: 0.0841 - acc: 0.9616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe3e3360d68>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model is: 0.88598573\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print('Test accuracy of model is:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Let us train a very simple CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cnn_small(n_timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 126, 12)           336       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 42, 12)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 504)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                16160     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 16,694\n",
      "Trainable params: 16,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "verbose, epochs, batch_size = 1, 25, 32\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "model = get_model_cnn_small(n_timesteps, n_features)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7352/7352 [==============================] - 1s 122us/sample - loss: 0.7146 - acc: 0.7088\n",
      "Epoch 2/25\n",
      "7352/7352 [==============================] - 1s 102us/sample - loss: 0.3067 - acc: 0.8915\n",
      "Epoch 3/25\n",
      "7352/7352 [==============================] - 1s 86us/sample - loss: 0.2097 - acc: 0.9264\n",
      "Epoch 4/25\n",
      "7352/7352 [==============================] - 1s 89us/sample - loss: 0.1707 - acc: 0.9361\n",
      "Epoch 5/25\n",
      "7352/7352 [==============================] - 1s 85us/sample - loss: 0.1480 - acc: 0.9429\n",
      "Epoch 6/25\n",
      "7352/7352 [==============================] - 1s 85us/sample - loss: 0.1359 - acc: 0.9446\n",
      "Epoch 7/25\n",
      "7352/7352 [==============================] - 1s 84us/sample - loss: 0.1229 - acc: 0.9514\n",
      "Epoch 8/25\n",
      "7352/7352 [==============================] - 1s 84us/sample - loss: 0.1166 - acc: 0.9528\n",
      "Epoch 9/25\n",
      "7352/7352 [==============================] - 1s 84us/sample - loss: 0.1133 - acc: 0.9536\n",
      "Epoch 10/25\n",
      "7352/7352 [==============================] - 1s 92us/sample - loss: 0.1123 - acc: 0.9520\n",
      "Epoch 11/25\n",
      "7352/7352 [==============================] - 1s 96us/sample - loss: 0.1047 - acc: 0.9573\n",
      "Epoch 12/25\n",
      "7352/7352 [==============================] - 1s 87us/sample - loss: 0.1028 - acc: 0.9561\n",
      "Epoch 13/25\n",
      "7352/7352 [==============================] - 1s 98us/sample - loss: 0.1019 - acc: 0.9576\n",
      "Epoch 14/25\n",
      "7352/7352 [==============================] - 1s 86us/sample - loss: 0.0976 - acc: 0.9589\n",
      "Epoch 15/25\n",
      "7352/7352 [==============================] - 1s 88us/sample - loss: 0.0963 - acc: 0.9580\n",
      "Epoch 16/25\n",
      "7352/7352 [==============================] - 1s 96us/sample - loss: 0.0933 - acc: 0.9614\n",
      "Epoch 17/25\n",
      "7352/7352 [==============================] - 1s 93us/sample - loss: 0.0948 - acc: 0.9618\n",
      "Epoch 18/25\n",
      "7352/7352 [==============================] - 1s 95us/sample - loss: 0.0894 - acc: 0.9635\n",
      "Epoch 19/25\n",
      "7352/7352 [==============================] - 1s 86us/sample - loss: 0.0830 - acc: 0.9657\n",
      "Epoch 20/25\n",
      "7352/7352 [==============================] - 1s 89us/sample - loss: 0.0819 - acc: 0.9646\n",
      "Epoch 21/25\n",
      "7352/7352 [==============================] - 1s 93us/sample - loss: 0.0936 - acc: 0.9619\n",
      "Epoch 22/25\n",
      "7352/7352 [==============================] - 1s 97us/sample - loss: 0.0787 - acc: 0.9675\n",
      "Epoch 23/25\n",
      "7352/7352 [==============================] - 1s 86us/sample - loss: 0.0748 - acc: 0.9676\n",
      "Epoch 24/25\n",
      "7352/7352 [==============================] - 1s 95us/sample - loss: 0.0759 - acc: 0.9671\n",
      "Epoch 25/25\n",
      "7352/7352 [==============================] - 1s 86us/sample - loss: 0.0732 - acc: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe3c27ebc18>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model is: 0.88496774\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print('Test accuracy of model is:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
