{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models on the UCI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 17:50:34.430560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        #print(data.shape)\n",
    "        loaded.append(data)\n",
    "        \n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Conv-BI-Directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 17:55:32.833454: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-05 17:55:32.834503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.683GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-05 17:55:32.835439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.683GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-05 17:55:32.835493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-05 17:55:32.835527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-05 17:55:32.835552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-05 17:55:32.835570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-05 17:55:32.835588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-05 17:55:32.835621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-05 17:55:32.835666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-05 17:55:32.835697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-05 17:55:32.838996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-03-05 17:55:32.839051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-05 17:55:32.839060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-03-05 17:55:32.839067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2022-03-05 17:55:32.839073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2022-03-05 17:55:32.841629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9677 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-03-05 17:55:32.842570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10269 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 124, 64)           2944      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 61, 32)            6176      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1, 1952)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 32)                252032    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 267,814\n",
      "Trainable params: 267,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Network Default input: [batch, timesteps, feature]\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3, strides=2, activation='relu'))\n",
    "model.add(tf.keras.layers.Reshape((-1,32*61)))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, activation='relu')))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8278 - acc: 0.6502\n",
      "Epoch 00001: val_acc improved from -inf to 0.79369, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 3s 370us/sample - loss: 0.8248 - acc: 0.6518 - val_loss: 0.5462 - val_acc: 0.7937\n",
      "Epoch 2/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.2530 - acc: 0.9045\n",
      "Epoch 00002: val_acc improved from 0.79369 to 0.87241, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 1s 187us/sample - loss: 0.2510 - acc: 0.9052 - val_loss: 0.3468 - val_acc: 0.8724\n",
      "Epoch 3/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.1524 - acc: 0.9429\n",
      "Epoch 00003: val_acc improved from 0.87241 to 0.88972, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 1s 188us/sample - loss: 0.1518 - acc: 0.9433 - val_loss: 0.2640 - val_acc: 0.8897\n",
      "Epoch 4/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.1343 - acc: 0.9452\n",
      "Epoch 00004: val_acc improved from 0.88972 to 0.90295, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 1s 190us/sample - loss: 0.1353 - acc: 0.9455 - val_loss: 0.2666 - val_acc: 0.9030\n",
      "Epoch 5/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.1366 - acc: 0.9470\n",
      "Epoch 00005: val_acc did not improve from 0.90295\n",
      "7352/7352 [==============================] - 1s 184us/sample - loss: 0.1345 - acc: 0.9478 - val_loss: 0.3990 - val_acc: 0.9030\n",
      "Epoch 6/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.1227 - acc: 0.9520\n",
      "Epoch 00006: val_acc improved from 0.90295 to 0.90974, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 1s 191us/sample - loss: 0.1218 - acc: 0.9524 - val_loss: 0.2647 - val_acc: 0.9097\n",
      "Epoch 7/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9537\n",
      "Epoch 00007: val_acc improved from 0.90974 to 0.91144, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 1s 190us/sample - loss: 0.1094 - acc: 0.9536 - val_loss: 0.3136 - val_acc: 0.9114\n",
      "Epoch 8/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9512\n",
      "Epoch 00008: val_acc did not improve from 0.91144\n",
      "7352/7352 [==============================] - 1s 181us/sample - loss: 0.1168 - acc: 0.9513 - val_loss: 0.4103 - val_acc: 0.8894\n",
      "Epoch 9/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.1116 - acc: 0.9531\n",
      "Epoch 00009: val_acc did not improve from 0.91144\n",
      "7352/7352 [==============================] - 1s 188us/sample - loss: 0.1116 - acc: 0.9531 - val_loss: 0.3616 - val_acc: 0.9026\n",
      "Epoch 10/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9559\n",
      "Epoch 00010: val_acc improved from 0.91144 to 0.91483, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 1s 191us/sample - loss: 0.0993 - acc: 0.9554 - val_loss: 0.3799 - val_acc: 0.9148\n",
      "Epoch 11/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9581\n",
      "Epoch 00011: val_acc did not improve from 0.91483\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0947 - acc: 0.9577 - val_loss: 0.4282 - val_acc: 0.9026\n",
      "Epoch 12/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9585\n",
      "Epoch 00012: val_acc did not improve from 0.91483\n",
      "7352/7352 [==============================] - 1s 186us/sample - loss: 0.0889 - acc: 0.9584 - val_loss: 0.3988 - val_acc: 0.9131\n",
      "Epoch 13/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9566\n",
      "Epoch 00013: val_acc did not improve from 0.91483\n",
      "7352/7352 [==============================] - 1s 179us/sample - loss: 0.0907 - acc: 0.9562 - val_loss: 0.5779 - val_acc: 0.8996\n",
      "Epoch 14/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9529\n",
      "Epoch 00014: val_acc did not improve from 0.91483\n",
      "7352/7352 [==============================] - 1s 181us/sample - loss: 0.1176 - acc: 0.9525 - val_loss: 0.3406 - val_acc: 0.9043\n",
      "Epoch 15/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9578\n",
      "Epoch 00015: val_acc did not improve from 0.91483\n",
      "7352/7352 [==============================] - 1s 187us/sample - loss: 0.0940 - acc: 0.9580 - val_loss: 0.3734 - val_acc: 0.9074\n",
      "Epoch 16/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9614\n",
      "Epoch 00016: val_acc improved from 0.91483 to 0.92569, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 1s 191us/sample - loss: 0.0846 - acc: 0.9608 - val_loss: 0.3318 - val_acc: 0.9257\n",
      "Epoch 17/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9608\n",
      "Epoch 00017: val_acc did not improve from 0.92569\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0784 - acc: 0.9606 - val_loss: 0.4434 - val_acc: 0.9162\n",
      "Epoch 18/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0791 - acc: 0.9619\n",
      "Epoch 00018: val_acc did not improve from 0.92569\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0791 - acc: 0.9619 - val_loss: 0.3991 - val_acc: 0.9243\n",
      "Epoch 19/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.1018 - acc: 0.9557\n",
      "Epoch 00019: val_acc did not improve from 0.92569\n",
      "7352/7352 [==============================] - 1s 188us/sample - loss: 0.1018 - acc: 0.9557 - val_loss: 0.3699 - val_acc: 0.8979\n",
      "Epoch 20/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0831 - acc: 0.9581\n",
      "Epoch 00020: val_acc did not improve from 0.92569\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0826 - acc: 0.9584 - val_loss: 0.3706 - val_acc: 0.9189\n",
      "Epoch 21/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0732 - acc: 0.9620\n",
      "Epoch 00021: val_acc improved from 0.92569 to 0.93485, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 1s 188us/sample - loss: 0.0741 - acc: 0.9619 - val_loss: 0.3559 - val_acc: 0.9348\n",
      "Epoch 22/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9626\n",
      "Epoch 00022: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0757 - acc: 0.9623 - val_loss: 0.3969 - val_acc: 0.9253\n",
      "Epoch 23/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9614\n",
      "Epoch 00023: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 184us/sample - loss: 0.0794 - acc: 0.9616 - val_loss: 0.4485 - val_acc: 0.9091\n",
      "Epoch 24/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9655\n",
      "Epoch 00024: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0700 - acc: 0.9660 - val_loss: 0.4145 - val_acc: 0.9040\n",
      "Epoch 25/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9660\n",
      "Epoch 00025: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0710 - acc: 0.9660 - val_loss: 0.4467 - val_acc: 0.9230\n",
      "Epoch 26/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0704 - acc: 0.9692\n",
      "Epoch 00026: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 178us/sample - loss: 0.0703 - acc: 0.9694 - val_loss: 0.7848 - val_acc: 0.8704\n",
      "Epoch 27/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9657\n",
      "Epoch 00027: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0762 - acc: 0.9659 - val_loss: 0.4287 - val_acc: 0.9226\n",
      "Epoch 28/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9689\n",
      "Epoch 00028: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0679 - acc: 0.9690 - val_loss: 0.4758 - val_acc: 0.9169\n",
      "Epoch 29/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0550 - acc: 0.9735\n",
      "Epoch 00029: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0565 - acc: 0.9728 - val_loss: 0.5094 - val_acc: 0.8999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0538 - acc: 0.9747\n",
      "Epoch 00030: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 178us/sample - loss: 0.0538 - acc: 0.9747 - val_loss: 0.5778 - val_acc: 0.9040\n",
      "Epoch 31/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9688\n",
      "Epoch 00031: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 188us/sample - loss: 0.0626 - acc: 0.9687 - val_loss: 0.5978 - val_acc: 0.9070\n",
      "Epoch 32/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0566 - acc: 0.9720\n",
      "Epoch 00032: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 186us/sample - loss: 0.0566 - acc: 0.9720 - val_loss: 0.5313 - val_acc: 0.9043\n",
      "Epoch 33/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0490 - acc: 0.9754\n",
      "Epoch 00033: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 184us/sample - loss: 0.0500 - acc: 0.9748 - val_loss: 0.6023 - val_acc: 0.8938\n",
      "Epoch 34/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9752\n",
      "Epoch 00034: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0517 - acc: 0.9751 - val_loss: 0.6714 - val_acc: 0.8968\n",
      "Epoch 35/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9690\n",
      "Epoch 00035: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 188us/sample - loss: 0.0642 - acc: 0.9689 - val_loss: 0.7888 - val_acc: 0.8843\n",
      "Epoch 36/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9751\n",
      "Epoch 00036: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 186us/sample - loss: 0.0574 - acc: 0.9747 - val_loss: 0.6297 - val_acc: 0.9046\n",
      "Epoch 37/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0506 - acc: 0.9758\n",
      "Epoch 00037: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 184us/sample - loss: 0.0509 - acc: 0.9757 - val_loss: 0.6790 - val_acc: 0.8996\n",
      "Epoch 38/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9769\n",
      "Epoch 00038: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 180us/sample - loss: 0.0560 - acc: 0.9763 - val_loss: 0.5374 - val_acc: 0.8918\n",
      "Epoch 39/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9729\n",
      "Epoch 00039: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0571 - acc: 0.9728 - val_loss: 0.4827 - val_acc: 0.9057\n",
      "Epoch 40/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0594 - acc: 0.9714\n",
      "Epoch 00040: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 181us/sample - loss: 0.0589 - acc: 0.9717 - val_loss: 0.5949 - val_acc: 0.9019\n",
      "Epoch 41/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9808\n",
      "Epoch 00041: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 180us/sample - loss: 0.0403 - acc: 0.9807 - val_loss: 0.5355 - val_acc: 0.9135\n",
      "Epoch 42/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0605 - acc: 0.9758\n",
      "Epoch 00042: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0605 - acc: 0.9758 - val_loss: 0.6845 - val_acc: 0.8907\n",
      "Epoch 43/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0666 - acc: 0.9751\n",
      "Epoch 00043: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 177us/sample - loss: 0.0666 - acc: 0.9751 - val_loss: 0.4474 - val_acc: 0.9053\n",
      "Epoch 44/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9787\n",
      "Epoch 00044: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0428 - acc: 0.9788 - val_loss: 0.5375 - val_acc: 0.9016\n",
      "Epoch 45/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9781\n",
      "Epoch 00045: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0474 - acc: 0.9780 - val_loss: 0.4388 - val_acc: 0.9074\n",
      "Epoch 46/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9763\n",
      "Epoch 00046: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 179us/sample - loss: 0.0492 - acc: 0.9763 - val_loss: 0.5587 - val_acc: 0.9125\n",
      "Epoch 47/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0417 - acc: 0.9801\n",
      "Epoch 00047: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 186us/sample - loss: 0.0423 - acc: 0.9800 - val_loss: 0.5554 - val_acc: 0.9192\n",
      "Epoch 48/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9788\n",
      "Epoch 00048: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0373 - acc: 0.9788 - val_loss: 0.5558 - val_acc: 0.9264\n",
      "Epoch 49/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9780\n",
      "Epoch 00049: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 180us/sample - loss: 0.0486 - acc: 0.9784 - val_loss: 0.5499 - val_acc: 0.9080\n",
      "Epoch 50/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9778\n",
      "Epoch 00050: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 181us/sample - loss: 0.0498 - acc: 0.9777 - val_loss: 0.4697 - val_acc: 0.9250\n",
      "Epoch 51/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0429 - acc: 0.9784\n",
      "Epoch 00051: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 186us/sample - loss: 0.0429 - acc: 0.9784 - val_loss: 0.4782 - val_acc: 0.9158\n",
      "Epoch 52/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9806\n",
      "Epoch 00052: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0424 - acc: 0.9805 - val_loss: 1.3233 - val_acc: 0.8850\n",
      "Epoch 53/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9768\n",
      "Epoch 00053: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0631 - acc: 0.9771 - val_loss: 0.5078 - val_acc: 0.9108\n",
      "Epoch 54/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0502 - acc: 0.9775\n",
      "Epoch 00054: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0501 - acc: 0.9774 - val_loss: 1.5106 - val_acc: 0.8938\n",
      "Epoch 55/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9785\n",
      "Epoch 00055: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 184us/sample - loss: 0.0458 - acc: 0.9786 - val_loss: 1.0150 - val_acc: 0.9131\n",
      "Epoch 56/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0347 - acc: 0.9848\n",
      "Epoch 00056: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0355 - acc: 0.9839 - val_loss: 1.0746 - val_acc: 0.8965\n",
      "Epoch 57/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9796\n",
      "Epoch 00057: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0431 - acc: 0.9797 - val_loss: 0.4628 - val_acc: 0.9080\n",
      "Epoch 58/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0320 - acc: 0.9845\n",
      "Epoch 00058: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 184us/sample - loss: 0.0323 - acc: 0.9846 - val_loss: 0.5663 - val_acc: 0.9084\n",
      "Epoch 59/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9837\n",
      "Epoch 00059: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0358 - acc: 0.9839 - val_loss: 0.5954 - val_acc: 0.9189\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9800\n",
      "Epoch 00060: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 190us/sample - loss: 0.0426 - acc: 0.9801 - val_loss: 0.6094 - val_acc: 0.9080\n",
      "Epoch 61/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0295 - acc: 0.9862\n",
      "Epoch 00061: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0309 - acc: 0.9857 - val_loss: 0.7371 - val_acc: 0.9118\n",
      "Epoch 62/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0398 - acc: 0.9823\n",
      "Epoch 00062: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0391 - acc: 0.9826 - val_loss: 0.6029 - val_acc: 0.9111\n",
      "Epoch 63/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0288 - acc: 0.9862\n",
      "Epoch 00063: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0283 - acc: 0.9864 - val_loss: 0.6652 - val_acc: 0.9091\n",
      "Epoch 64/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0265 - acc: 0.9876\n",
      "Epoch 00064: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 188us/sample - loss: 0.0265 - acc: 0.9876 - val_loss: 0.6439 - val_acc: 0.9067\n",
      "Epoch 65/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9842\n",
      "Epoch 00065: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 178us/sample - loss: 0.0337 - acc: 0.9844 - val_loss: 0.7620 - val_acc: 0.9009\n",
      "Epoch 66/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0510 - acc: 0.9794\n",
      "Epoch 00066: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 188us/sample - loss: 0.0501 - acc: 0.9797 - val_loss: 0.7009 - val_acc: 0.9043\n",
      "Epoch 67/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0292 - acc: 0.9876\n",
      "Epoch 00067: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 186us/sample - loss: 0.0289 - acc: 0.9875 - val_loss: 0.7067 - val_acc: 0.9006\n",
      "Epoch 68/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9856\n",
      "Epoch 00068: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0282 - acc: 0.9857 - val_loss: 0.9929 - val_acc: 0.8955\n",
      "Epoch 69/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0445 - acc: 0.9829\n",
      "Epoch 00069: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 181us/sample - loss: 0.0445 - acc: 0.9829 - val_loss: 0.7871 - val_acc: 0.8982\n",
      "Epoch 70/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9875\n",
      "Epoch 00070: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0266 - acc: 0.9876 - val_loss: 0.9881 - val_acc: 0.8968\n",
      "Epoch 71/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9867\n",
      "Epoch 00071: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0319 - acc: 0.9867 - val_loss: 0.9601 - val_acc: 0.8955\n",
      "Epoch 72/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9860\n",
      "Epoch 00072: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 179us/sample - loss: 0.0330 - acc: 0.9859 - val_loss: 0.9936 - val_acc: 0.9033\n",
      "Epoch 73/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0268 - acc: 0.9876\n",
      "Epoch 00073: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0265 - acc: 0.9879 - val_loss: 1.0063 - val_acc: 0.9033\n",
      "Epoch 74/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0273 - acc: 0.9870\n",
      "Epoch 00074: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0273 - acc: 0.9871 - val_loss: 1.0547 - val_acc: 0.9013\n",
      "Epoch 75/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0235 - acc: 0.9901\n",
      "Epoch 00075: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0254 - acc: 0.9897 - val_loss: 1.2305 - val_acc: 0.8982\n",
      "Epoch 76/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0269 - acc: 0.9879\n",
      "Epoch 00076: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 186us/sample - loss: 0.0267 - acc: 0.9880 - val_loss: 1.1540 - val_acc: 0.9023\n",
      "Epoch 77/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9912\n",
      "Epoch 00077: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0224 - acc: 0.9913 - val_loss: 1.3236 - val_acc: 0.9019\n",
      "Epoch 78/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9833\n",
      "Epoch 00078: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 179us/sample - loss: 0.0584 - acc: 0.9810 - val_loss: 0.8298 - val_acc: 0.8772\n",
      "Epoch 79/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0568 - acc: 0.9810\n",
      "Epoch 00079: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 184us/sample - loss: 0.0550 - acc: 0.9816 - val_loss: 0.4691 - val_acc: 0.9070\n",
      "Epoch 80/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0196 - acc: 0.9911\n",
      "Epoch 00080: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 184us/sample - loss: 0.0197 - acc: 0.9913 - val_loss: 0.5408 - val_acc: 0.9101\n",
      "Epoch 81/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0234 - acc: 0.9901\n",
      "Epoch 00081: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0230 - acc: 0.9902 - val_loss: 0.6155 - val_acc: 0.9104\n",
      "Epoch 82/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0227 - acc: 0.9901\n",
      "Epoch 00082: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0235 - acc: 0.9895 - val_loss: 0.6738 - val_acc: 0.9135\n",
      "Epoch 83/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0253 - acc: 0.9897\n",
      "Epoch 00083: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0252 - acc: 0.9895 - val_loss: 0.5923 - val_acc: 0.9148\n",
      "Epoch 84/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9945\n",
      "Epoch 00084: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 186us/sample - loss: 0.0150 - acc: 0.9946 - val_loss: 0.8203 - val_acc: 0.9097\n",
      "Epoch 85/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0207 - acc: 0.9916\n",
      "Epoch 00085: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 180us/sample - loss: 0.0208 - acc: 0.9916 - val_loss: 0.7071 - val_acc: 0.9077\n",
      "Epoch 86/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9914\n",
      "Epoch 00086: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 180us/sample - loss: 0.0202 - acc: 0.9910 - val_loss: 0.5911 - val_acc: 0.9172\n",
      "Epoch 87/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0274 - acc: 0.9904\n",
      "Epoch 00087: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0268 - acc: 0.9906 - val_loss: 0.6536 - val_acc: 0.9145\n",
      "Epoch 88/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0213 - acc: 0.9905\n",
      "Epoch 00088: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 186us/sample - loss: 0.0214 - acc: 0.9902 - val_loss: 0.6771 - val_acc: 0.9169\n",
      "Epoch 89/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0167 - acc: 0.9929\n",
      "Epoch 00089: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 187us/sample - loss: 0.0179 - acc: 0.9927 - val_loss: 0.6029 - val_acc: 0.9162\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9891\n",
      "Epoch 00090: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 187us/sample - loss: 0.0206 - acc: 0.9891 - val_loss: 0.7056 - val_acc: 0.9141\n",
      "Epoch 91/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9881\n",
      "Epoch 00091: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0242 - acc: 0.9882 - val_loss: 0.6383 - val_acc: 0.9152\n",
      "Epoch 92/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.9946\n",
      "Epoch 00092: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0150 - acc: 0.9946 - val_loss: 0.5976 - val_acc: 0.9165\n",
      "Epoch 93/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9870\n",
      "Epoch 00093: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 184us/sample - loss: 0.0321 - acc: 0.9874 - val_loss: 0.6263 - val_acc: 0.9087\n",
      "Epoch 94/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0142 - acc: 0.9952\n",
      "Epoch 00094: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 175us/sample - loss: 0.0146 - acc: 0.9951 - val_loss: 0.6394 - val_acc: 0.9104\n",
      "Epoch 95/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9921\n",
      "Epoch 00095: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 181us/sample - loss: 0.0242 - acc: 0.9921 - val_loss: 0.7702 - val_acc: 0.9091\n",
      "Epoch 96/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9914\n",
      "Epoch 00096: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 184us/sample - loss: 0.0232 - acc: 0.9914 - val_loss: 0.7716 - val_acc: 0.9230\n",
      "Epoch 97/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0149 - acc: 0.9941\n",
      "Epoch 00097: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 185us/sample - loss: 0.0147 - acc: 0.9942 - val_loss: 0.8014 - val_acc: 0.9141\n",
      "Epoch 98/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0243 - acc: 0.9898\n",
      "Epoch 00098: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 181us/sample - loss: 0.0236 - acc: 0.9902 - val_loss: 0.7835 - val_acc: 0.9148\n",
      "Epoch 99/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9940\n",
      "Epoch 00099: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 181us/sample - loss: 0.0139 - acc: 0.9940 - val_loss: 0.7609 - val_acc: 0.9111\n",
      "Epoch 100/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0188 - acc: 0.9927\n",
      "Epoch 00100: val_acc did not improve from 0.93485\n",
      "7352/7352 [==============================] - 1s 183us/sample - loss: 0.0198 - acc: 0.9920 - val_loss: 0.9795 - val_acc: 0.9104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2c3ca4bc10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'BiLSTM_Best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, epochs=100,\n",
    "            verbose=1, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model, accuracy: 93.48%\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate the model\n",
    "model.load_weights(filepath)\n",
    "\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"LSTM model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
