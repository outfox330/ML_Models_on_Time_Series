{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM models on the UCI datasets\n",
    "- LSTM Models are slow to train. The newly proposed TCNs are shown to be simpler and easier to train, along with better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "        \n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Dropout, Flatten, Bidirectional\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Permute, Reshape\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 128, 16)           1664      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 3,878\n",
      "Trainable params: 3,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "num_hidden_lstm = 16\n",
    "win_len = 128\n",
    "dim = 9\n",
    "num_classes = 6\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(num_hidden_lstm, \n",
    "               input_shape=(win_len,dim), \n",
    "               return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(num_hidden_lstm, return_sequences=False))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.6375 - accuracy: 0.7293\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.6926 - accuracy: 0.7168\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.5473 - accuracy: 0.7637\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.5087 - accuracy: 0.7758\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.4211 - accuracy: 0.8207\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 0.3796 - accuracy: 0.8531\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.2945 - accuracy: 0.9045\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2670 - accuracy: 0.9124\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.2104 - accuracy: 0.9339\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2171 - accuracy: 0.9302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe77c1f5c50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "verbose = 1\n",
    "model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model is: 0.8720732927322388\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print('Test accuracy of model is:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple MLP to classify this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 77,126\n",
      "Trainable params: 77,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_hidden_lstm = 16\n",
    "win_len = 128\n",
    "dim = 9\n",
    "num_classes = 6\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(win_len*dim,), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.9610 - accuracy: 0.6109\n",
      "Epoch 2/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.4925 - accuracy: 0.8116\n",
      "Epoch 3/100\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.3670 - accuracy: 0.8644\n",
      "Epoch 4/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.2923 - accuracy: 0.8898\n",
      "Epoch 5/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.2649 - accuracy: 0.8981\n",
      "Epoch 6/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.2384 - accuracy: 0.9094\n",
      "Epoch 7/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.2253 - accuracy: 0.9119\n",
      "Epoch 8/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.2191 - accuracy: 0.9144\n",
      "Epoch 9/100\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.1937 - accuracy: 0.9267\n",
      "Epoch 10/100\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.1773 - accuracy: 0.9305\n",
      "Epoch 11/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1869 - accuracy: 0.9300\n",
      "Epoch 12/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.1687 - accuracy: 0.9335\n",
      "Epoch 13/100\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.1702 - accuracy: 0.9324\n",
      "Epoch 14/100\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1596 - accuracy: 0.9366\n",
      "Epoch 15/100\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.1641 - accuracy: 0.9363\n",
      "Epoch 16/100\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.1576 - accuracy: 0.9385\n",
      "Epoch 17/100\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.1510 - accuracy: 0.9393\n",
      "Epoch 18/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.1550 - accuracy: 0.9368\n",
      "Epoch 19/100\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.1513 - accuracy: 0.9408\n",
      "Epoch 20/100\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.1506 - accuracy: 0.9381\n",
      "Epoch 21/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.1481 - accuracy: 0.9406\n",
      "Epoch 22/100\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.1469 - accuracy: 0.9397\n",
      "Epoch 23/100\n",
      "7352/7352 [==============================] - 0s 47us/step - loss: 0.1299 - accuracy: 0.9464\n",
      "Epoch 24/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.1386 - accuracy: 0.9436\n",
      "Epoch 25/100\n",
      "7352/7352 [==============================] - 0s 55us/step - loss: 0.1425 - accuracy: 0.9415\n",
      "Epoch 26/100\n",
      "7352/7352 [==============================] - 0s 63us/step - loss: 0.1403 - accuracy: 0.9437\n",
      "Epoch 27/100\n",
      "7352/7352 [==============================] - 0s 59us/step - loss: 0.1342 - accuracy: 0.9453\n",
      "Epoch 28/100\n",
      "7352/7352 [==============================] - 0s 58us/step - loss: 0.1370 - accuracy: 0.9419\n",
      "Epoch 29/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.1302 - accuracy: 0.9467\n",
      "Epoch 30/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.1299 - accuracy: 0.9470\n",
      "Epoch 31/100\n",
      "7352/7352 [==============================] - 0s 55us/step - loss: 0.1345 - accuracy: 0.9448\n",
      "Epoch 32/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.1303 - accuracy: 0.9494\n",
      "Epoch 33/100\n",
      "7352/7352 [==============================] - 0s 61us/step - loss: 0.1212 - accuracy: 0.9491\n",
      "Epoch 34/100\n",
      "7352/7352 [==============================] - 0s 62us/step - loss: 0.1167 - accuracy: 0.9479\n",
      "Epoch 35/100\n",
      "7352/7352 [==============================] - 0s 61us/step - loss: 0.1322 - accuracy: 0.9427\n",
      "Epoch 36/100\n",
      "7352/7352 [==============================] - 0s 59us/step - loss: 0.1247 - accuracy: 0.9512\n",
      "Epoch 37/100\n",
      "7352/7352 [==============================] - 0s 58us/step - loss: 0.1322 - accuracy: 0.9472\n",
      "Epoch 38/100\n",
      "7352/7352 [==============================] - 0s 66us/step - loss: 0.1299 - accuracy: 0.9464\n",
      "Epoch 39/100\n",
      "7352/7352 [==============================] - 0s 59us/step - loss: 0.1195 - accuracy: 0.9484\n",
      "Epoch 40/100\n",
      "7352/7352 [==============================] - 0s 57us/step - loss: 0.1237 - accuracy: 0.9468\n",
      "Epoch 41/100\n",
      "7352/7352 [==============================] - 0s 57us/step - loss: 0.1208 - accuracy: 0.9524\n",
      "Epoch 42/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.1170 - accuracy: 0.9514\n",
      "Epoch 43/100\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.1234 - accuracy: 0.9476\n",
      "Epoch 44/100\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.1274 - accuracy: 0.9494\n",
      "Epoch 45/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.1176 - accuracy: 0.9513\n",
      "Epoch 46/100\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.1179 - accuracy: 0.9508\n",
      "Epoch 47/100\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.1149 - accuracy: 0.9535\n",
      "Epoch 48/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.1229 - accuracy: 0.9478\n",
      "Epoch 49/100\n",
      "7352/7352 [==============================] - 0s 54us/step - loss: 0.1157 - accuracy: 0.9542\n",
      "Epoch 50/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.1119 - accuracy: 0.9538\n",
      "Epoch 51/100\n",
      "7352/7352 [==============================] - 0s 53us/step - loss: 0.1185 - accuracy: 0.9513\n",
      "Epoch 52/100\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.1187 - accuracy: 0.9535\n",
      "Epoch 53/100\n",
      "7352/7352 [==============================] - 0s 47us/step - loss: 0.1160 - accuracy: 0.9521\n",
      "Epoch 54/100\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.1115 - accuracy: 0.9554\n",
      "Epoch 55/100\n",
      "7352/7352 [==============================] - 0s 51us/step - loss: 0.1199 - accuracy: 0.9531\n",
      "Epoch 56/100\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.1241 - accuracy: 0.9490\n",
      "Epoch 57/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.1195 - accuracy: 0.9529\n",
      "Epoch 58/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.1161 - accuracy: 0.9506\n",
      "Epoch 59/100\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.1058 - accuracy: 0.9547\n",
      "Epoch 60/100\n",
      "7352/7352 [==============================] - 0s 53us/step - loss: 0.1075 - accuracy: 0.9563\n",
      "Epoch 61/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.1169 - accuracy: 0.9523\n",
      "Epoch 62/100\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1043 - accuracy: 0.9551\n",
      "Epoch 63/100\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.1025 - accuracy: 0.9584\n",
      "Epoch 64/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.1233 - accuracy: 0.9517\n",
      "Epoch 65/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.1152 - accuracy: 0.9538\n",
      "Epoch 66/100\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.1176 - accuracy: 0.9508\n",
      "Epoch 67/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.1144 - accuracy: 0.9525\n",
      "Epoch 68/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.1112 - accuracy: 0.9551\n",
      "Epoch 69/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.1021 - accuracy: 0.9561\n",
      "Epoch 70/100\n",
      "7352/7352 [==============================] - 0s 58us/step - loss: 0.1106 - accuracy: 0.9542\n",
      "Epoch 71/100\n",
      "7352/7352 [==============================] - 0s 63us/step - loss: 0.1074 - accuracy: 0.9562\n",
      "Epoch 72/100\n",
      "7352/7352 [==============================] - 0s 57us/step - loss: 0.1068 - accuracy: 0.9532\n",
      "Epoch 73/100\n",
      "7352/7352 [==============================] - 0s 57us/step - loss: 0.1077 - accuracy: 0.9562\n",
      "Epoch 74/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.1061 - accuracy: 0.9569\n",
      "Epoch 75/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.1169 - accuracy: 0.9550\n",
      "Epoch 76/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.1129 - accuracy: 0.9555\n",
      "Epoch 77/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.0960 - accuracy: 0.9599\n",
      "Epoch 78/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.1084 - accuracy: 0.9551\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 47us/step - loss: 0.1130 - accuracy: 0.9538\n",
      "Epoch 80/100\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.1046 - accuracy: 0.9585\n",
      "Epoch 81/100\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.0977 - accuracy: 0.9595\n",
      "Epoch 82/100\n",
      "7352/7352 [==============================] - 0s 60us/step - loss: 0.1030 - accuracy: 0.9574\n",
      "Epoch 83/100\n",
      "7352/7352 [==============================] - 0s 58us/step - loss: 0.1041 - accuracy: 0.9566\n",
      "Epoch 84/100\n",
      "7352/7352 [==============================] - 0s 64us/step - loss: 0.1030 - accuracy: 0.9573\n",
      "Epoch 85/100\n",
      "7352/7352 [==============================] - 0s 59us/step - loss: 0.1076 - accuracy: 0.9565\n",
      "Epoch 86/100\n",
      "7352/7352 [==============================] - 0s 53us/step - loss: 0.0989 - accuracy: 0.9584\n",
      "Epoch 87/100\n",
      "7352/7352 [==============================] - 0s 55us/step - loss: 0.0939 - accuracy: 0.9595\n",
      "Epoch 88/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.1113 - accuracy: 0.9557\n",
      "Epoch 89/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.1048 - accuracy: 0.9582\n",
      "Epoch 90/100\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1046 - accuracy: 0.9569\n",
      "Epoch 91/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.0981 - accuracy: 0.9608\n",
      "Epoch 92/100\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1026 - accuracy: 0.9577\n",
      "Epoch 93/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1032 - accuracy: 0.9595\n",
      "Epoch 94/100\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1016 - accuracy: 0.9585\n",
      "Epoch 95/100\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.0989 - accuracy: 0.9593\n",
      "Epoch 96/100\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.1065 - accuracy: 0.9576\n",
      "Epoch 97/100\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0935 - accuracy: 0.9623\n",
      "Epoch 98/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0937 - accuracy: 0.9610\n",
      "Epoch 99/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1009 - accuracy: 0.9595\n",
      "Epoch 100/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0946 - accuracy: 0.9599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe77df8dfd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "verbose = 1\n",
    "model.fit(trainX.reshape(-1,win_len*dim ), trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model is: 0.8819137811660767\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "_, accuracy = model.evaluate(testX.reshape(-1,win_len*dim ), testy, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print('Test accuracy of model is:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
