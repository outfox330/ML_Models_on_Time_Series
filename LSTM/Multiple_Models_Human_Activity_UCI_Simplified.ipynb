{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM models on the UCI datasets\n",
    "- LSTM Models are slow to train. The newly proposed TCNs are shown to be simpler and easier to train, along with better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        #print(data.shape)\n",
    "        loaded.append(data)\n",
    "        \n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let us create a MLP network first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
      "(7352, 1152)\n",
      "(2947, 1152)\n"
     ]
    }
   ],
   "source": [
    "# MLP with take 1-D data as an input\n",
    "\n",
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()\n",
    "\n",
    "trainX = trainX.reshape(7352,-1)\n",
    "print(trainX.shape)\n",
    "\n",
    "testX = testX.reshape(2947, -1)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 80,230\n",
      "Trainable params: 80,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MLP Network\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75365, saving model to MLP_Best.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.75365 to 0.85748, saving model to MLP_Best.hdf5\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.85748\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85748 to 0.87106, saving model to MLP_Best.hdf5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87106 to 0.87784, saving model to MLP_Best.hdf5\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87784\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87784\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.87784 to 0.88157, saving model to MLP_Best.hdf5\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.88157\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.88157\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.88157\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.88157\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.88157\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.88157\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.88157 to 0.88429, saving model to MLP_Best.hdf5\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.88429 to 0.88836, saving model to MLP_Best.hdf5\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.88836\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.88836\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.88836 to 0.89040, saving model to MLP_Best.hdf5\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.89040\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.89040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f92a2454400>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'MLP_Best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, nb_epoch=100,\n",
    "            verbose=0, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 - 0s - loss: 0.7471 - acc: 0.8904\n",
      "MLP model, accuracy: 89.04%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filepath)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"MLP model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us do a 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, 124, 64)           2944      \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 61, 32)            6176      \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1952)              0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 32)                62496     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 71,814\n",
      "Trainable params: 71,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1-D CNN Network\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3, strides=2, activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.7941 - acc: 0.6720\n",
      "Epoch 00001: val_acc improved from -inf to 0.81201, saving model to 1D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 6s 806us/sample - loss: 0.7920 - acc: 0.6726 - val_loss: 0.5194 - val_acc: 0.8120\n",
      "Epoch 2/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.3321 - acc: 0.8760\n",
      "Epoch 00002: val_acc improved from 0.81201 to 0.87479, saving model to 1D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 2s 254us/sample - loss: 0.3316 - acc: 0.8757 - val_loss: 0.3728 - val_acc: 0.8748\n",
      "Epoch 3/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9206\n",
      "Epoch 00003: val_acc improved from 0.87479 to 0.88802, saving model to 1D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 2s 312us/sample - loss: 0.2205 - acc: 0.9207 - val_loss: 0.3517 - val_acc: 0.8880\n",
      "Epoch 4/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9354\n",
      "Epoch 00004: val_acc improved from 0.88802 to 0.90601, saving model to 1D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 2s 276us/sample - loss: 0.1706 - acc: 0.9359 - val_loss: 0.3134 - val_acc: 0.9060\n",
      "Epoch 5/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1477 - acc: 0.9401\n",
      "Epoch 00005: val_acc improved from 0.90601 to 0.91551, saving model to 1D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 2s 338us/sample - loss: 0.1479 - acc: 0.9400 - val_loss: 0.2745 - val_acc: 0.9155\n",
      "Epoch 6/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9449\n",
      "Epoch 00006: val_acc improved from 0.91551 to 0.91890, saving model to 1D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 2s 281us/sample - loss: 0.1361 - acc: 0.9453 - val_loss: 0.2607 - val_acc: 0.9189\n",
      "Epoch 7/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9489\n",
      "Epoch 00007: val_acc did not improve from 0.91890\n",
      "7352/7352 [==============================] - 2s 261us/sample - loss: 0.1287 - acc: 0.9494 - val_loss: 0.3076 - val_acc: 0.9016\n",
      "Epoch 8/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9481\n",
      "Epoch 00008: val_acc did not improve from 0.91890\n",
      "7352/7352 [==============================] - 2s 262us/sample - loss: 0.1252 - acc: 0.9482 - val_loss: 0.3004 - val_acc: 0.9121\n",
      "Epoch 9/40\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.1201 - acc: 0.9516\n",
      "Epoch 00009: val_acc did not improve from 0.91890\n",
      "7352/7352 [==============================] - 2s 262us/sample - loss: 0.1192 - acc: 0.9521 - val_loss: 0.2843 - val_acc: 0.9125\n",
      "Epoch 10/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9509\n",
      "Epoch 00010: val_acc improved from 0.91890 to 0.93010, saving model to 1D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 2s 286us/sample - loss: 0.1127 - acc: 0.9510 - val_loss: 0.2540 - val_acc: 0.9301\n",
      "Epoch 11/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9487\n",
      "Epoch 00011: val_acc did not improve from 0.93010\n",
      "7352/7352 [==============================] - 3s 344us/sample - loss: 0.1159 - acc: 0.9493 - val_loss: 0.3244 - val_acc: 0.9114\n",
      "Epoch 12/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9540\n",
      "Epoch 00012: val_acc did not improve from 0.93010\n",
      "7352/7352 [==============================] - 3s 382us/sample - loss: 0.1083 - acc: 0.9536 - val_loss: 0.3381 - val_acc: 0.9240\n",
      "Epoch 13/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9508\n",
      "Epoch 00013: val_acc did not improve from 0.93010\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.1072 - acc: 0.9504 - val_loss: 0.3574 - val_acc: 0.9203\n",
      "Epoch 14/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9549\n",
      "Epoch 00014: val_acc did not improve from 0.93010\n",
      "7352/7352 [==============================] - 2s 293us/sample - loss: 0.1054 - acc: 0.9547 - val_loss: 0.3339 - val_acc: 0.9165\n",
      "Epoch 15/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9537\n",
      "Epoch 00015: val_acc improved from 0.93010 to 0.93213, saving model to 1D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 2s 308us/sample - loss: 0.0963 - acc: 0.9536 - val_loss: 0.3727 - val_acc: 0.9321\n",
      "Epoch 16/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9537- ETA: 1s\n",
      "Epoch 00016: val_acc did not improve from 0.93213\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0995 - acc: 0.9538 - val_loss: 0.4738 - val_acc: 0.9053\n",
      "Epoch 17/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9562\n",
      "Epoch 00017: val_acc did not improve from 0.93213\n",
      "7352/7352 [==============================] - 2s 281us/sample - loss: 0.0951 - acc: 0.9562 - val_loss: 0.3791 - val_acc: 0.9223\n",
      "Epoch 18/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9558\n",
      "Epoch 00018: val_acc did not improve from 0.93213\n",
      "7352/7352 [==============================] - 2s 266us/sample - loss: 0.0915 - acc: 0.9559 - val_loss: 0.3491 - val_acc: 0.9247\n",
      "Epoch 19/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9544\n",
      "Epoch 00019: val_acc did not improve from 0.93213\n",
      "7352/7352 [==============================] - 2s 256us/sample - loss: 0.1014 - acc: 0.9543 - val_loss: 0.4001 - val_acc: 0.9199\n",
      "Epoch 20/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9591\n",
      "Epoch 00020: val_acc improved from 0.93213 to 0.93858, saving model to 1D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 2s 259us/sample - loss: 0.0835 - acc: 0.9591 - val_loss: 0.3960 - val_acc: 0.9386\n",
      "Epoch 21/40\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0930 - acc: 0.9543\n",
      "Epoch 00021: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 243us/sample - loss: 0.0919 - acc: 0.9547 - val_loss: 0.4885 - val_acc: 0.9118\n",
      "Epoch 22/40\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0949 - acc: 0.9550\n",
      "Epoch 00022: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 248us/sample - loss: 0.0943 - acc: 0.9553 - val_loss: 0.3753 - val_acc: 0.9182\n",
      "Epoch 23/40\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0829 - acc: 0.9581\n",
      "Epoch 00023: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 244us/sample - loss: 0.0825 - acc: 0.9581 - val_loss: 0.4765 - val_acc: 0.9165\n",
      "Epoch 24/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9598\n",
      "Epoch 00024: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 259us/sample - loss: 0.0796 - acc: 0.9595 - val_loss: 0.4830 - val_acc: 0.9094\n",
      "Epoch 25/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9574\n",
      "Epoch 00025: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 251us/sample - loss: 0.0857 - acc: 0.9572 - val_loss: 0.4341 - val_acc: 0.9158\n",
      "Epoch 26/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9577\n",
      "Epoch 00026: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 238us/sample - loss: 0.0805 - acc: 0.9577 - val_loss: 0.5293 - val_acc: 0.9253\n",
      "Epoch 27/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9608\n",
      "Epoch 00027: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 228us/sample - loss: 0.0724 - acc: 0.9610 - val_loss: 0.5161 - val_acc: 0.9247\n",
      "Epoch 28/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9604\n",
      "Epoch 00028: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 226us/sample - loss: 0.0719 - acc: 0.9606 - val_loss: 0.6014 - val_acc: 0.9308\n",
      "Epoch 29/40\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0754 - acc: 0.9639\n",
      "Epoch 00029: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 215us/sample - loss: 0.0753 - acc: 0.9640 - val_loss: 0.4387 - val_acc: 0.9220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0751 - acc: 0.9618\n",
      "Epoch 00030: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 207us/sample - loss: 0.0748 - acc: 0.9618 - val_loss: 0.4852 - val_acc: 0.9158\n",
      "Epoch 31/40\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0890 - acc: 0.9586\n",
      "Epoch 00031: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 221us/sample - loss: 0.0880 - acc: 0.9592 - val_loss: 0.4797 - val_acc: 0.9203\n",
      "Epoch 32/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9622\n",
      "Epoch 00032: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 209us/sample - loss: 0.0703 - acc: 0.9626 - val_loss: 0.5319 - val_acc: 0.9230\n",
      "Epoch 33/40\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0752 - acc: 0.9635\n",
      "Epoch 00033: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 1s 201us/sample - loss: 0.0761 - acc: 0.9629 - val_loss: 0.5855 - val_acc: 0.9253\n",
      "Epoch 34/40\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0629 - acc: 0.9668\n",
      "Epoch 00034: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 1s 203us/sample - loss: 0.0633 - acc: 0.9667 - val_loss: 0.4696 - val_acc: 0.9284\n",
      "Epoch 35/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9640\n",
      "Epoch 00035: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 2s 206us/sample - loss: 0.0657 - acc: 0.9641 - val_loss: 0.4873 - val_acc: 0.9192\n",
      "Epoch 36/40\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9689\n",
      "Epoch 00036: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 1s 190us/sample - loss: 0.0643 - acc: 0.9689 - val_loss: 0.5430 - val_acc: 0.9175\n",
      "Epoch 37/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9640\n",
      "Epoch 00037: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 1s 186us/sample - loss: 0.0722 - acc: 0.9641 - val_loss: 0.4759 - val_acc: 0.9253\n",
      "Epoch 38/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9629\n",
      "Epoch 00038: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 1s 176us/sample - loss: 0.0663 - acc: 0.9630 - val_loss: 0.5925 - val_acc: 0.9284\n",
      "Epoch 39/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9663\n",
      "Epoch 00039: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 1s 181us/sample - loss: 0.0647 - acc: 0.9657 - val_loss: 0.4646 - val_acc: 0.9237\n",
      "Epoch 40/40\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0608 - acc: 0.9668\n",
      "Epoch 00040: val_acc did not improve from 0.93858\n",
      "7352/7352 [==============================] - 1s 182us/sample - loss: 0.0606 - acc: 0.9668 - val_loss: 0.4753 - val_acc: 0.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9290bb8d68>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '1D_CNN_Best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, nb_epoch=40,\n",
    "            verbose=1, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 - 0s - loss: 0.3960 - acc: 0.9386\n",
      "1D CNN model, accuracy: 93.86%\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate the model\n",
    "model.load_weights(filepath)\n",
    "\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"1D CNN model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
      "(7352, 128, 9, 1)\n",
      "(2947, 128, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = load_dataset()\n",
    "\n",
    "trainX = trainX.reshape(7352,trainX.shape[1], trainX.shape[2], 1)\n",
    "print(trainX.shape)\n",
    "\n",
    "testX = testX.reshape(2947, testX.shape[1], testX.shape[2], 1)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 124, 5, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 61, 2, 32)         18464     \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 3904)              0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 32)                124960    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 145,286\n",
      "Trainable params: 145,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2-D CNN Network\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1], trainX.shape[2], 1)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9616\n",
      "Epoch 00001: val_acc did not improve from 0.92942\n",
      "7352/7352 [==============================] - 4s 525us/sample - loss: 0.0746 - acc: 0.9611 - val_loss: 0.3359 - val_acc: 0.9233\n",
      "Epoch 2/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9643\n",
      "Epoch 00002: val_acc did not improve from 0.92942\n",
      "7352/7352 [==============================] - 4s 569us/sample - loss: 0.0753 - acc: 0.9641 - val_loss: 0.4221 - val_acc: 0.9223\n",
      "Epoch 3/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9670\n",
      "Epoch 00003: val_acc did not improve from 0.92942\n",
      "7352/7352 [==============================] - 4s 601us/sample - loss: 0.0741 - acc: 0.9669 - val_loss: 0.5645 - val_acc: 0.9148\n",
      "Epoch 4/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9640\n",
      "Epoch 00004: val_acc did not improve from 0.92942\n",
      "7352/7352 [==============================] - 5s 667us/sample - loss: 0.0806 - acc: 0.9641 - val_loss: 0.5765 - val_acc: 0.9213\n",
      "Epoch 5/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9622\n",
      "Epoch 00005: val_acc did not improve from 0.92942\n",
      "7352/7352 [==============================] - 5s 661us/sample - loss: 0.0822 - acc: 0.9623 - val_loss: 0.5382 - val_acc: 0.9155\n",
      "Epoch 6/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9671\n",
      "Epoch 00006: val_acc improved from 0.92942 to 0.93994, saving model to 2D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 5s 647us/sample - loss: 0.0641 - acc: 0.9674 - val_loss: 0.3873 - val_acc: 0.9399\n",
      "Epoch 7/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9734\n",
      "Epoch 00007: val_acc did not improve from 0.93994\n",
      "7352/7352 [==============================] - 6s 751us/sample - loss: 0.0557 - acc: 0.9736 - val_loss: 0.3989 - val_acc: 0.9332\n",
      "Epoch 8/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9728\n",
      "Epoch 00008: val_acc did not improve from 0.93994\n",
      "7352/7352 [==============================] - 5s 731us/sample - loss: 0.0571 - acc: 0.9727 - val_loss: 0.4486 - val_acc: 0.9304\n",
      "Epoch 9/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9730\n",
      "Epoch 00009: val_acc did not improve from 0.93994\n",
      "7352/7352 [==============================] - 5s 731us/sample - loss: 0.0609 - acc: 0.9731 - val_loss: 0.4425 - val_acc: 0.9237\n",
      "Epoch 10/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9748\n",
      "Epoch 00010: val_acc did not improve from 0.93994\n",
      "7352/7352 [==============================] - 6s 781us/sample - loss: 0.0549 - acc: 0.9747 - val_loss: 0.5724 - val_acc: 0.9260\n",
      "Epoch 11/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9749\n",
      "Epoch 00011: val_acc did not improve from 0.93994\n",
      "7352/7352 [==============================] - 6s 789us/sample - loss: 0.0502 - acc: 0.9748 - val_loss: 0.5393 - val_acc: 0.9209\n",
      "Epoch 12/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9781\n",
      "Epoch 00012: val_acc did not improve from 0.93994\n",
      "7352/7352 [==============================] - 7s 901us/sample - loss: 0.0487 - acc: 0.9780 - val_loss: 0.6422 - val_acc: 0.9189\n",
      "Epoch 13/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9764\n",
      "Epoch 00013: val_acc did not improve from 0.93994\n",
      "7352/7352 [==============================] - 7s 901us/sample - loss: 0.0508 - acc: 0.9765 - val_loss: 0.6072 - val_acc: 0.9084\n",
      "Epoch 14/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9745\n",
      "Epoch 00014: val_acc did not improve from 0.93994\n",
      "7352/7352 [==============================] - 7s 896us/sample - loss: 0.0555 - acc: 0.9747 - val_loss: 0.4454 - val_acc: 0.9267\n",
      "Epoch 15/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9771\n",
      "Epoch 00015: val_acc improved from 0.93994 to 0.94062, saving model to 2D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 6s 875us/sample - loss: 0.0496 - acc: 0.9766 - val_loss: 0.4705 - val_acc: 0.9406\n",
      "Epoch 16/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9811\n",
      "Epoch 00016: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 6s 823us/sample - loss: 0.0414 - acc: 0.9812 - val_loss: 0.5447 - val_acc: 0.9257\n",
      "Epoch 17/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9771\n",
      "Epoch 00017: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 6s 806us/sample - loss: 0.0470 - acc: 0.9770 - val_loss: 0.5336 - val_acc: 0.9315\n",
      "Epoch 18/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9757\n",
      "Epoch 00018: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 6s 803us/sample - loss: 0.0589 - acc: 0.9757 - val_loss: 0.5098 - val_acc: 0.9382\n",
      "Epoch 19/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9789\n",
      "Epoch 00019: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 6s 758us/sample - loss: 0.0435 - acc: 0.9789 - val_loss: 0.5859 - val_acc: 0.9281\n",
      "Epoch 20/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9799\n",
      "Epoch 00020: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 735us/sample - loss: 0.0432 - acc: 0.9799 - val_loss: 0.6956 - val_acc: 0.9189\n",
      "Epoch 21/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9806\n",
      "Epoch 00021: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 715us/sample - loss: 0.0435 - acc: 0.9807 - val_loss: 0.7259 - val_acc: 0.9108\n",
      "Epoch 22/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9823\n",
      "Epoch 00022: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 720us/sample - loss: 0.0399 - acc: 0.9822 - val_loss: 0.7767 - val_acc: 0.9291\n",
      "Epoch 23/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9806\n",
      "Epoch 00023: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 683us/sample - loss: 0.0415 - acc: 0.9805 - val_loss: 0.5929 - val_acc: 0.9270\n",
      "Epoch 24/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9857\n",
      "Epoch 00024: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 686us/sample - loss: 0.0355 - acc: 0.9857 - val_loss: 0.6379 - val_acc: 0.9294\n",
      "Epoch 25/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9798\n",
      "Epoch 00025: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 694us/sample - loss: 0.0490 - acc: 0.9799 - val_loss: 0.4688 - val_acc: 0.9396\n",
      "Epoch 26/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9830\n",
      "Epoch 00026: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 701us/sample - loss: 0.0365 - acc: 0.9830 - val_loss: 0.6270 - val_acc: 0.9253\n",
      "Epoch 27/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9818\n",
      "Epoch 00027: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 709us/sample - loss: 0.0470 - acc: 0.9816 - val_loss: 0.6388 - val_acc: 0.9287\n",
      "Epoch 28/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9845\n",
      "Epoch 00028: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 727us/sample - loss: 0.0374 - acc: 0.9842 - val_loss: 0.5568 - val_acc: 0.9389\n",
      "Epoch 29/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9868\n",
      "Epoch 00029: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 6s 765us/sample - loss: 0.0340 - acc: 0.9868 - val_loss: 0.6190 - val_acc: 0.9304\n",
      "Epoch 30/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9860\n",
      "Epoch 00030: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 6s 770us/sample - loss: 0.0320 - acc: 0.9861 - val_loss: 0.7164 - val_acc: 0.9223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9868\n",
      "Epoch 00031: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 739us/sample - loss: 0.0330 - acc: 0.9869 - val_loss: 0.8296 - val_acc: 0.9253\n",
      "Epoch 32/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9840\n",
      "Epoch 00032: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 728us/sample - loss: 0.0379 - acc: 0.9839 - val_loss: 0.6082 - val_acc: 0.9304\n",
      "Epoch 33/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9835\n",
      "Epoch 00033: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 727us/sample - loss: 0.0378 - acc: 0.9831 - val_loss: 0.7657 - val_acc: 0.9332\n",
      "Epoch 34/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9874\n",
      "Epoch 00034: val_acc did not improve from 0.94062\n",
      "7352/7352 [==============================] - 5s 722us/sample - loss: 0.0323 - acc: 0.9875 - val_loss: 0.7301 - val_acc: 0.9325\n",
      "Epoch 35/40\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9871\n",
      "Epoch 00035: val_acc improved from 0.94062 to 0.94231, saving model to 2D_CNN_Best.hdf5\n",
      "7352/7352 [==============================] - 6s 751us/sample - loss: 0.0308 - acc: 0.9868 - val_loss: 0.6234 - val_acc: 0.9423\n",
      "Epoch 36/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9870\n",
      "Epoch 00036: val_acc did not improve from 0.94231\n",
      "7352/7352 [==============================] - 6s 828us/sample - loss: 0.0280 - acc: 0.9871 - val_loss: 0.6222 - val_acc: 0.9406\n",
      "Epoch 37/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9826\n",
      "Epoch 00037: val_acc did not improve from 0.94231\n",
      "7352/7352 [==============================] - 6s 870us/sample - loss: 0.0522 - acc: 0.9820 - val_loss: 0.9350 - val_acc: 0.8968\n",
      "Epoch 38/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9826\n",
      "Epoch 00038: val_acc did not improve from 0.94231\n",
      "7352/7352 [==============================] - 7s 932us/sample - loss: 0.0402 - acc: 0.9825 - val_loss: 1.3251 - val_acc: 0.9165\n",
      "Epoch 39/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9862\n",
      "Epoch 00039: val_acc did not improve from 0.94231\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0318 - acc: 0.9860 - val_loss: 1.0982 - val_acc: 0.9345\n",
      "Epoch 40/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9855\n",
      "Epoch 00040: val_acc did not improve from 0.94231\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0398 - acc: 0.9854 - val_loss: 0.9758 - val_acc: 0.9291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9290bb8668>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '2D_CNN_Best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, nb_epoch=40,\n",
    "            verbose=1, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 - 0s - loss: 0.6234 - acc: 0.9423\n",
      "2D CNN model, accuracy: 94.23%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filepath)\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"2D CNN model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using only ACC and GYRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        #print(data.shape)\n",
    "        loaded.append(data)\n",
    "        \n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 6) (7352, 6) (2947, 128, 6) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_17 (Conv1D)           (None, 124, 64)           1984      \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 61, 32)            6176      \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1952)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 32)                62496     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 70,854\n",
      "Trainable params: 70,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1-D CNN Network\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3, strides=2, activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 1.1814 - acc: 0.4634\n",
      "Epoch 00001: val_acc improved from -inf to 0.63488, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 3s 390us/sample - loss: 1.1747 - acc: 0.4653 - val_loss: 0.7236 - val_acc: 0.6349\n",
      "Epoch 2/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.6879 - acc: 0.6380\n",
      "Epoch 00002: val_acc improved from 0.63488 to 0.64065, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 150us/sample - loss: 0.6851 - acc: 0.6396 - val_loss: 0.6841 - val_acc: 0.6407\n",
      "Epoch 3/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.6285 - acc: 0.6544\n",
      "Epoch 00003: val_acc improved from 0.64065 to 0.68035, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 152us/sample - loss: 0.6266 - acc: 0.6552 - val_loss: 0.6179 - val_acc: 0.6804\n",
      "Epoch 4/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.5820 - acc: 0.6948\n",
      "Epoch 00004: val_acc did not improve from 0.68035\n",
      "7352/7352 [==============================] - 1s 149us/sample - loss: 0.5828 - acc: 0.6946 - val_loss: 0.6480 - val_acc: 0.6634\n",
      "Epoch 5/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.5567 - acc: 0.7150\n",
      "Epoch 00005: val_acc did not improve from 0.68035\n",
      "7352/7352 [==============================] - 1s 149us/sample - loss: 0.5562 - acc: 0.7155 - val_loss: 0.6384 - val_acc: 0.6566\n",
      "Epoch 6/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.5380 - acc: 0.7341\n",
      "Epoch 00006: val_acc improved from 0.68035 to 0.74313, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 148us/sample - loss: 0.5352 - acc: 0.7369 - val_loss: 0.5784 - val_acc: 0.7431\n",
      "Epoch 7/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.4806 - acc: 0.7818\n",
      "Epoch 00007: val_acc improved from 0.74313 to 0.83848, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 154us/sample - loss: 0.4833 - acc: 0.7810 - val_loss: 0.4952 - val_acc: 0.8385\n",
      "Epoch 8/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8054\n",
      "Epoch 00008: val_acc improved from 0.83848 to 0.85205, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 160us/sample - loss: 0.4442 - acc: 0.8058 - val_loss: 0.4875 - val_acc: 0.8521\n",
      "Epoch 9/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.4078 - acc: 0.8340\n",
      "Epoch 00009: val_acc did not improve from 0.85205\n",
      "7352/7352 [==============================] - 1s 161us/sample - loss: 0.4092 - acc: 0.8317 - val_loss: 0.5361 - val_acc: 0.7662\n",
      "Epoch 10/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.4076 - acc: 0.8234\n",
      "Epoch 00010: val_acc improved from 0.85205 to 0.86257, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 149us/sample - loss: 0.4057 - acc: 0.8247 - val_loss: 0.4294 - val_acc: 0.8626\n",
      "Epoch 11/100\n",
      "6912/7352 [===========================>..] - ETA: 0s - loss: 0.3493 - acc: 0.8598\n",
      "Epoch 00011: val_acc improved from 0.86257 to 0.86393, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 154us/sample - loss: 0.3496 - acc: 0.8581 - val_loss: 0.4115 - val_acc: 0.8639\n",
      "Epoch 12/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.3397 - acc: 0.8623\n",
      "Epoch 00012: val_acc did not improve from 0.86393\n",
      "7352/7352 [==============================] - 1s 153us/sample - loss: 0.3400 - acc: 0.8624 - val_loss: 0.3921 - val_acc: 0.8558\n",
      "Epoch 13/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.8651\n",
      "Epoch 00013: val_acc improved from 0.86393 to 0.88700, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 154us/sample - loss: 0.3220 - acc: 0.8647 - val_loss: 0.3915 - val_acc: 0.8870\n",
      "Epoch 14/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.2963 - acc: 0.8835\n",
      "Epoch 00014: val_acc improved from 0.88700 to 0.89752, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 155us/sample - loss: 0.2972 - acc: 0.8823 - val_loss: 0.3518 - val_acc: 0.8975\n",
      "Epoch 15/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.3056 - acc: 0.8747\n",
      "Epoch 00015: val_acc did not improve from 0.89752\n",
      "7352/7352 [==============================] - 1s 146us/sample - loss: 0.3044 - acc: 0.8753 - val_loss: 0.3685 - val_acc: 0.8758\n",
      "Epoch 16/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.2823 - acc: 0.8856\n",
      "Epoch 00016: val_acc improved from 0.89752 to 0.89786, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 149us/sample - loss: 0.2826 - acc: 0.8852 - val_loss: 0.3136 - val_acc: 0.8979\n",
      "Epoch 17/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.8995\n",
      "Epoch 00017: val_acc improved from 0.89786 to 0.89990, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 164us/sample - loss: 0.2549 - acc: 0.8999 - val_loss: 0.2997 - val_acc: 0.8999\n",
      "Epoch 18/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.2507 - acc: 0.9061\n",
      "Epoch 00018: val_acc did not improve from 0.89990\n",
      "7352/7352 [==============================] - 1s 148us/sample - loss: 0.2516 - acc: 0.9056 - val_loss: 0.3945 - val_acc: 0.8880\n",
      "Epoch 19/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.2452 - acc: 0.9020\n",
      "Epoch 00019: val_acc did not improve from 0.89990\n",
      "7352/7352 [==============================] - 1s 149us/sample - loss: 0.2437 - acc: 0.9026 - val_loss: 0.3407 - val_acc: 0.8860\n",
      "Epoch 20/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.2405 - acc: 0.9054\n",
      "Epoch 00020: val_acc did not improve from 0.89990\n",
      "7352/7352 [==============================] - 1s 144us/sample - loss: 0.2408 - acc: 0.9053 - val_loss: 0.3188 - val_acc: 0.8996\n",
      "Epoch 21/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9161\n",
      "Epoch 00021: val_acc improved from 0.89990 to 0.91042, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 151us/sample - loss: 0.2139 - acc: 0.9159 - val_loss: 0.2864 - val_acc: 0.9104\n",
      "Epoch 22/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9196\n",
      "Epoch 00022: val_acc did not improve from 0.91042\n",
      "7352/7352 [==============================] - 1s 145us/sample - loss: 0.2058 - acc: 0.9204 - val_loss: 0.4633 - val_acc: 0.8490\n",
      "Epoch 23/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.2141 - acc: 0.9168\n",
      "Epoch 00023: val_acc did not improve from 0.91042\n",
      "7352/7352 [==============================] - 1s 142us/sample - loss: 0.2149 - acc: 0.9168 - val_loss: 0.2876 - val_acc: 0.9009\n",
      "Epoch 24/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9259\n",
      "Epoch 00024: val_acc did not improve from 0.91042\n",
      "7352/7352 [==============================] - 1s 147us/sample - loss: 0.1991 - acc: 0.9252 - val_loss: 0.3715 - val_acc: 0.8873\n",
      "Epoch 25/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9258\n",
      "Epoch 00025: val_acc did not improve from 0.91042\n",
      "7352/7352 [==============================] - 1s 145us/sample - loss: 0.1987 - acc: 0.9253 - val_loss: 0.3086 - val_acc: 0.9067\n",
      "Epoch 26/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.1935 - acc: 0.9286\n",
      "Epoch 00026: val_acc did not improve from 0.91042\n",
      "7352/7352 [==============================] - 1s 144us/sample - loss: 0.1937 - acc: 0.9285 - val_loss: 0.3589 - val_acc: 0.9077\n",
      "Epoch 27/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.1855 - acc: 0.9283\n",
      "Epoch 00027: val_acc improved from 0.91042 to 0.91381, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 156us/sample - loss: 0.1834 - acc: 0.9289 - val_loss: 0.2953 - val_acc: 0.9138\n",
      "Epoch 28/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9367\n",
      "Epoch 00028: val_acc did not improve from 0.91381\n",
      "7352/7352 [==============================] - 1s 148us/sample - loss: 0.1747 - acc: 0.9359 - val_loss: 0.3091 - val_acc: 0.9104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1725 - acc: 0.9342\n",
      "Epoch 00029: val_acc did not improve from 0.91381\n",
      "7352/7352 [==============================] - 1s 148us/sample - loss: 0.1731 - acc: 0.9340 - val_loss: 0.3034 - val_acc: 0.9057\n",
      "Epoch 30/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.1633 - acc: 0.9399\n",
      "Epoch 00030: val_acc improved from 0.91381 to 0.91449, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 155us/sample - loss: 0.1653 - acc: 0.9392 - val_loss: 0.3269 - val_acc: 0.9145\n",
      "Epoch 31/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9390\n",
      "Epoch 00031: val_acc did not improve from 0.91449\n",
      "7352/7352 [==============================] - 1s 150us/sample - loss: 0.1634 - acc: 0.9392 - val_loss: 0.3390 - val_acc: 0.9125\n",
      "Epoch 32/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.1856 - acc: 0.9305\n",
      "Epoch 00032: val_acc improved from 0.91449 to 0.92060, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 150us/sample - loss: 0.1849 - acc: 0.9300 - val_loss: 0.2976 - val_acc: 0.9206\n",
      "Epoch 33/100\n",
      "6912/7352 [===========================>..] - ETA: 0s - loss: 0.1481 - acc: 0.9453\n",
      "Epoch 00033: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 143us/sample - loss: 0.1480 - acc: 0.9452 - val_loss: 0.3399 - val_acc: 0.9080\n",
      "Epoch 34/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9431\n",
      "Epoch 00034: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 147us/sample - loss: 0.1506 - acc: 0.9436 - val_loss: 0.3363 - val_acc: 0.9063\n",
      "Epoch 35/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9461\n",
      "Epoch 00035: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 146us/sample - loss: 0.1472 - acc: 0.9456 - val_loss: 0.4364 - val_acc: 0.9057\n",
      "Epoch 36/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1555 - acc: 0.9413\n",
      "Epoch 00036: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 143us/sample - loss: 0.1549 - acc: 0.9415 - val_loss: 0.5003 - val_acc: 0.8887\n",
      "Epoch 37/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9415\n",
      "Epoch 00037: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 149us/sample - loss: 0.1537 - acc: 0.9422 - val_loss: 0.4176 - val_acc: 0.8965\n",
      "Epoch 38/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.1412 - acc: 0.9448\n",
      "Epoch 00038: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 142us/sample - loss: 0.1404 - acc: 0.9452 - val_loss: 0.4116 - val_acc: 0.8911\n",
      "Epoch 39/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.1320 - acc: 0.9521\n",
      "Epoch 00039: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 145us/sample - loss: 0.1331 - acc: 0.9517 - val_loss: 0.4735 - val_acc: 0.8911\n",
      "Epoch 40/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9499\n",
      "Epoch 00040: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 146us/sample - loss: 0.1350 - acc: 0.9499 - val_loss: 0.3756 - val_acc: 0.9087\n",
      "Epoch 41/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9524\n",
      "Epoch 00041: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 149us/sample - loss: 0.1289 - acc: 0.9527 - val_loss: 0.3649 - val_acc: 0.9114\n",
      "Epoch 42/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9526\n",
      "Epoch 00042: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 147us/sample - loss: 0.1314 - acc: 0.9524 - val_loss: 0.4291 - val_acc: 0.8948\n",
      "Epoch 43/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9505\n",
      "Epoch 00043: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 147us/sample - loss: 0.1347 - acc: 0.9502 - val_loss: 0.3942 - val_acc: 0.9023\n",
      "Epoch 44/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9474\n",
      "Epoch 00044: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 147us/sample - loss: 0.1495 - acc: 0.9475 - val_loss: 0.3960 - val_acc: 0.8965\n",
      "Epoch 45/100\n",
      "6912/7352 [===========================>..] - ETA: 0s - loss: 0.1158 - acc: 0.9576\n",
      "Epoch 00045: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 154us/sample - loss: 0.1164 - acc: 0.9563 - val_loss: 0.3220 - val_acc: 0.9192\n",
      "Epoch 46/100\n",
      "6912/7352 [===========================>..] - ETA: 0s - loss: 0.1247 - acc: 0.9552\n",
      "Epoch 00046: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 148us/sample - loss: 0.1235 - acc: 0.9553 - val_loss: 0.3483 - val_acc: 0.9070\n",
      "Epoch 47/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.1278 - acc: 0.9533\n",
      "Epoch 00047: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 149us/sample - loss: 0.1276 - acc: 0.9536 - val_loss: 0.3662 - val_acc: 0.9074\n",
      "Epoch 48/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.1275 - acc: 0.9531\n",
      "Epoch 00048: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 143us/sample - loss: 0.1259 - acc: 0.9538 - val_loss: 0.3794 - val_acc: 0.9111\n",
      "Epoch 49/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.1164 - acc: 0.9569\n",
      "Epoch 00049: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 152us/sample - loss: 0.1164 - acc: 0.9569 - val_loss: 0.3711 - val_acc: 0.9169\n",
      "Epoch 50/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9577\n",
      "Epoch 00050: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 152us/sample - loss: 0.1144 - acc: 0.9580 - val_loss: 0.3800 - val_acc: 0.9179\n",
      "Epoch 51/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.1082 - acc: 0.9600\n",
      "Epoch 00051: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 160us/sample - loss: 0.1077 - acc: 0.9603 - val_loss: 0.4425 - val_acc: 0.9114\n",
      "Epoch 52/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9621\n",
      "Epoch 00052: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 159us/sample - loss: 0.1047 - acc: 0.9622 - val_loss: 0.4028 - val_acc: 0.9074\n",
      "Epoch 53/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.1113 - acc: 0.9607\n",
      "Epoch 00053: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 150us/sample - loss: 0.1109 - acc: 0.9607 - val_loss: 0.3763 - val_acc: 0.9135\n",
      "Epoch 54/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9621\n",
      "Epoch 00054: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 163us/sample - loss: 0.1043 - acc: 0.9618 - val_loss: 0.4806 - val_acc: 0.9050\n",
      "Epoch 55/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.1240 - acc: 0.9533\n",
      "Epoch 00055: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 151us/sample - loss: 0.1242 - acc: 0.9531 - val_loss: 0.4532 - val_acc: 0.8989\n",
      "Epoch 56/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.1174 - acc: 0.9558\n",
      "Epoch 00056: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 180us/sample - loss: 0.1161 - acc: 0.9566 - val_loss: 0.3715 - val_acc: 0.9121\n",
      "Epoch 57/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9647\n",
      "Epoch 00057: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 178us/sample - loss: 0.0954 - acc: 0.9650 - val_loss: 0.4346 - val_acc: 0.9016\n",
      "Epoch 58/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9630\n",
      "Epoch 00058: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 159us/sample - loss: 0.0971 - acc: 0.9630 - val_loss: 0.4450 - val_acc: 0.9040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0931 - acc: 0.9662\n",
      "Epoch 00059: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 157us/sample - loss: 0.0963 - acc: 0.9650 - val_loss: 0.4089 - val_acc: 0.9155\n",
      "Epoch 60/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9635- ETA: 0s - loss: 0.0967 - acc\n",
      "Epoch 00060: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 151us/sample - loss: 0.0978 - acc: 0.9635 - val_loss: 0.4705 - val_acc: 0.9135\n",
      "Epoch 61/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.1011 - acc: 0.9643\n",
      "Epoch 00061: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 146us/sample - loss: 0.1012 - acc: 0.9642 - val_loss: 0.4890 - val_acc: 0.9019\n",
      "Epoch 62/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.1019 - acc: 0.9631\n",
      "Epoch 00062: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 147us/sample - loss: 0.1022 - acc: 0.9629 - val_loss: 0.4359 - val_acc: 0.9114\n",
      "Epoch 63/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0916 - acc: 0.9673\n",
      "Epoch 00063: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 150us/sample - loss: 0.0911 - acc: 0.9674 - val_loss: 0.4155 - val_acc: 0.9135\n",
      "Epoch 64/100\n",
      "7040/7352 [===========================>..] - ETA: 0s - loss: 0.0883 - acc: 0.9692\n",
      "Epoch 00064: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 146us/sample - loss: 0.0882 - acc: 0.9695 - val_loss: 0.4696 - val_acc: 0.9097\n",
      "Epoch 65/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9658\n",
      "Epoch 00065: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 147us/sample - loss: 0.0913 - acc: 0.9661 - val_loss: 0.3983 - val_acc: 0.9175\n",
      "Epoch 66/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0881 - acc: 0.9682\n",
      "Epoch 00066: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 154us/sample - loss: 0.0871 - acc: 0.9689 - val_loss: 0.4220 - val_acc: 0.9186\n",
      "Epoch 67/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0850 - acc: 0.9682\n",
      "Epoch 00067: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 159us/sample - loss: 0.0850 - acc: 0.9684 - val_loss: 0.6845 - val_acc: 0.8962\n",
      "Epoch 68/100\n",
      "6976/7352 [===========================>..] - ETA: 0s - loss: 0.0808 - acc: 0.9708\n",
      "Epoch 00068: val_acc did not improve from 0.92060\n",
      "7352/7352 [==============================] - 1s 163us/sample - loss: 0.0810 - acc: 0.9702 - val_loss: 0.5134 - val_acc: 0.9145\n",
      "Epoch 69/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9690\n",
      "Epoch 00069: val_acc improved from 0.92060 to 0.92094, saving model to 1D_CNN_Best_2.hdf5\n",
      "7352/7352 [==============================] - 1s 173us/sample - loss: 0.0857 - acc: 0.9695 - val_loss: 0.4455 - val_acc: 0.9209\n",
      "Epoch 70/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0747 - acc: 0.9723\n",
      "Epoch 00070: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 1s 175us/sample - loss: 0.0751 - acc: 0.9725 - val_loss: 0.5089 - val_acc: 0.9179\n",
      "Epoch 71/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9717\n",
      "Epoch 00071: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 1s 197us/sample - loss: 0.0815 - acc: 0.9716 - val_loss: 0.5736 - val_acc: 0.9023\n",
      "Epoch 72/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9704\n",
      "Epoch 00072: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 1s 198us/sample - loss: 0.0836 - acc: 0.9705 - val_loss: 0.4718 - val_acc: 0.9131\n",
      "Epoch 73/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0795 - acc: 0.9710\n",
      "Epoch 00073: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 208us/sample - loss: 0.0790 - acc: 0.9713 - val_loss: 0.5142 - val_acc: 0.9125\n",
      "Epoch 74/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9730\n",
      "Epoch 00074: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 212us/sample - loss: 0.0734 - acc: 0.9729 - val_loss: 0.4897 - val_acc: 0.9175\n",
      "Epoch 75/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0919 - acc: 0.9675\n",
      "Epoch 00075: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 223us/sample - loss: 0.0921 - acc: 0.9668 - val_loss: 0.6202 - val_acc: 0.9009\n",
      "Epoch 76/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9757\n",
      "Epoch 00076: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 237us/sample - loss: 0.0740 - acc: 0.9752 - val_loss: 0.5494 - val_acc: 0.9131\n",
      "Epoch 77/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9719\n",
      "Epoch 00077: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 239us/sample - loss: 0.0754 - acc: 0.9717 - val_loss: 0.5397 - val_acc: 0.9135\n",
      "Epoch 78/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9732\n",
      "Epoch 00078: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 268us/sample - loss: 0.0705 - acc: 0.9736 - val_loss: 0.6739 - val_acc: 0.8945\n",
      "Epoch 79/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9717\n",
      "Epoch 00079: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 287us/sample - loss: 0.0722 - acc: 0.9724 - val_loss: 0.6439 - val_acc: 0.9125\n",
      "Epoch 80/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9752\n",
      "Epoch 00080: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 281us/sample - loss: 0.0704 - acc: 0.9751 - val_loss: 0.6126 - val_acc: 0.9145\n",
      "Epoch 81/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9748\n",
      "Epoch 00081: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 284us/sample - loss: 0.0688 - acc: 0.9746 - val_loss: 0.6863 - val_acc: 0.9091\n",
      "Epoch 82/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0662 - acc: 0.9772\n",
      "Epoch 00082: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 294us/sample - loss: 0.0665 - acc: 0.9770 - val_loss: 0.5697 - val_acc: 0.9104\n",
      "Epoch 83/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9735\n",
      "Epoch 00083: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 308us/sample - loss: 0.0771 - acc: 0.9735 - val_loss: 0.6126 - val_acc: 0.8982\n",
      "Epoch 84/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9762\n",
      "Epoch 00084: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 3s 395us/sample - loss: 0.0665 - acc: 0.9761 - val_loss: 0.5527 - val_acc: 0.9121\n",
      "Epoch 85/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9750\n",
      "Epoch 00085: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 3s 355us/sample - loss: 0.0676 - acc: 0.9752 - val_loss: 0.5856 - val_acc: 0.9101\n",
      "Epoch 86/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9790\n",
      "Epoch 00086: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 3s 420us/sample - loss: 0.0577 - acc: 0.9791 - val_loss: 0.5900 - val_acc: 0.9152\n",
      "Epoch 87/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9776\n",
      "Epoch 00087: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 3s 380us/sample - loss: 0.0641 - acc: 0.9776 - val_loss: 0.5611 - val_acc: 0.9138\n",
      "Epoch 88/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9770\n",
      "Epoch 00088: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 3s 420us/sample - loss: 0.0721 - acc: 0.9766 - val_loss: 0.5364 - val_acc: 0.9209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9791\n",
      "Epoch 00089: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 3s 415us/sample - loss: 0.0594 - acc: 0.9793 - val_loss: 0.5704 - val_acc: 0.9172\n",
      "Epoch 90/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9816\n",
      "Epoch 00090: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 3s 415us/sample - loss: 0.0529 - acc: 0.9818 - val_loss: 0.6442 - val_acc: 0.8999\n",
      "Epoch 91/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9747\n",
      "Epoch 00091: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 3s 366us/sample - loss: 0.0653 - acc: 0.9747 - val_loss: 0.6187 - val_acc: 0.9128\n",
      "Epoch 92/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9795\n",
      "Epoch 00092: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 3s 342us/sample - loss: 0.0552 - acc: 0.9796 - val_loss: 0.6683 - val_acc: 0.9053\n",
      "Epoch 93/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9800\n",
      "Epoch 00093: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0571 - acc: 0.9800 - val_loss: 0.7656 - val_acc: 0.9080\n",
      "Epoch 94/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9809\n",
      "Epoch 00094: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 308us/sample - loss: 0.0550 - acc: 0.9811 - val_loss: 0.6301 - val_acc: 0.9131\n",
      "Epoch 95/100\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9808\n",
      "Epoch 00095: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 293us/sample - loss: 0.0608 - acc: 0.9810 - val_loss: 0.6486 - val_acc: 0.9114\n",
      "Epoch 96/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9764\n",
      "Epoch 00096: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 278us/sample - loss: 0.0637 - acc: 0.9767 - val_loss: 0.6878 - val_acc: 0.9125\n",
      "Epoch 97/100\n",
      "7104/7352 [===========================>..] - ETA: 0s - loss: 0.0552 - acc: 0.9813\n",
      "Epoch 00097: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 266us/sample - loss: 0.0559 - acc: 0.9808 - val_loss: 0.7170 - val_acc: 0.9125\n",
      "Epoch 98/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9819\n",
      "Epoch 00098: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 258us/sample - loss: 0.0505 - acc: 0.9807 - val_loss: 0.6641 - val_acc: 0.9084\n",
      "Epoch 99/100\n",
      "7232/7352 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9827\n",
      "Epoch 00099: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 248us/sample - loss: 0.0476 - acc: 0.9826 - val_loss: 0.7753 - val_acc: 0.8935\n",
      "Epoch 100/100\n",
      "7168/7352 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9810\n",
      "Epoch 00100: val_acc did not improve from 0.92094\n",
      "7352/7352 [==============================] - 2s 232us/sample - loss: 0.0510 - acc: 0.9811 - val_loss: 0.6763 - val_acc: 0.9125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9290bb8908>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '1D_CNN_Best_2.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, nb_epoch=100,\n",
    "            verbose=1, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 - 0s - loss: 0.4455 - acc: 0.9209\n",
      "1D CNN model, accuracy: 92.09%\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate the model\n",
    "model.load_weights(filepath)\n",
    "\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"1D CNN model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        #print(data.shape)\n",
    "        loaded.append(data)\n",
    "        \n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 16)                1664      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 2,406\n",
      "Trainable params: 2,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Network Default input: [batch, timesteps, feature]\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(tf.keras.layers.LSTM(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "WARNING:tensorflow:From /Users/sandeep/miniconda3/envs/mango/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 2.4648 - acc: 0.3768\n",
      "Epoch 00001: val_acc improved from -inf to 0.54801, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 10s 1ms/sample - loss: 2.4560 - acc: 0.3789 - val_loss: 1.7507 - val_acc: 0.5480\n",
      "Epoch 2/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 2441.6731 - acc: 0.5228\n",
      "Epoch 00002: val_acc improved from 0.54801 to 0.56295, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 2423.0853 - acc: 0.5227 - val_loss: 1.3928 - val_acc: 0.5629\n",
      "Epoch 3/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 1.4325 - acc: 0.5513\n",
      "Epoch 00003: val_acc did not improve from 0.56295\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 1.4330 - acc: 0.5509 - val_loss: 1.3081 - val_acc: 0.5382\n",
      "Epoch 4/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 1.2651 - acc: 0.5703\n",
      "Epoch 00004: val_acc improved from 0.56295 to 0.56396, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 1.2668 - acc: 0.5699 - val_loss: 1.2246 - val_acc: 0.5640\n",
      "Epoch 5/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 1.2676 - acc: 0.5814\n",
      "Epoch 00005: val_acc improved from 0.56396 to 0.57855, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 10s 1ms/sample - loss: 1.2663 - acc: 0.5811 - val_loss: 1.1711 - val_acc: 0.5786\n",
      "Epoch 6/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 1.1469 - acc: 0.5848\n",
      "Epoch 00006: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 10s 1ms/sample - loss: 1.1468 - acc: 0.5850 - val_loss: 1.1448 - val_acc: 0.5619\n",
      "Epoch 7/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 150.7848 - acc: 0.5537\n",
      "Epoch 00007: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 10s 1ms/sample - loss: 149.6449 - acc: 0.5530 - val_loss: 1.2166 - val_acc: 0.5263\n",
      "Epoch 8/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 1.1653 - acc: 0.5540\n",
      "Epoch 00008: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 12s 2ms/sample - loss: 1.1653 - acc: 0.5537 - val_loss: 1.1793 - val_acc: 0.5358\n",
      "Epoch 9/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 1.1211 - acc: 0.5706\n",
      "Epoch 00009: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 21s 3ms/sample - loss: 1.1216 - acc: 0.5706 - val_loss: 1.1463 - val_acc: 0.5470\n",
      "Epoch 10/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 1.0867 - acc: 0.5850\n",
      "Epoch 00010: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 27s 4ms/sample - loss: 1.0866 - acc: 0.5849 - val_loss: 1.1175 - val_acc: 0.5470\n",
      "Epoch 11/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 1.0610 - acc: 0.5900\n",
      "Epoch 00011: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 17s 2ms/sample - loss: 1.0603 - acc: 0.5909 - val_loss: 1.0918 - val_acc: 0.5528\n",
      "Epoch 12/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 1.0301 - acc: 0.5942\n",
      "Epoch 00012: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 14s 2ms/sample - loss: 1.0305 - acc: 0.5941 - val_loss: 1.0665 - val_acc: 0.5541\n",
      "Epoch 13/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.9978 - acc: 0.6051\n",
      "Epoch 00013: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 12s 2ms/sample - loss: 0.9993 - acc: 0.6036 - val_loss: 1.0386 - val_acc: 0.5633\n",
      "Epoch 14/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.9694 - acc: 0.6102\n",
      "Epoch 00014: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 11s 2ms/sample - loss: 0.9695 - acc: 0.6103 - val_loss: 1.0170 - val_acc: 0.5694\n",
      "Epoch 15/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.9540 - acc: 0.6031\n",
      "Epoch 00015: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 11s 2ms/sample - loss: 0.9542 - acc: 0.6035 - val_loss: 0.9972 - val_acc: 0.5711\n",
      "Epoch 16/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.9278 - acc: 0.6168\n",
      "Epoch 00016: val_acc did not improve from 0.57855\n",
      "7352/7352 [==============================] - 13s 2ms/sample - loss: 0.9284 - acc: 0.6168 - val_loss: 0.9797 - val_acc: 0.5755\n",
      "Epoch 17/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.9147 - acc: 0.6175\n",
      "Epoch 00017: val_acc improved from 0.57855 to 0.58398, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 13s 2ms/sample - loss: 0.9139 - acc: 0.6179 - val_loss: 0.9639 - val_acc: 0.5840\n",
      "Epoch 18/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8957 - acc: 0.6249\n",
      "Epoch 00018: val_acc did not improve from 0.58398\n",
      "7352/7352 [==============================] - 15s 2ms/sample - loss: 0.8960 - acc: 0.6246 - val_loss: 0.9491 - val_acc: 0.5833\n",
      "Epoch 19/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8841 - acc: 0.6232- ETA: 3s \n",
      "Epoch 00019: val_acc did not improve from 0.58398\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.8848 - acc: 0.6228 - val_loss: 0.9380 - val_acc: 0.5826\n",
      "Epoch 20/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8690 - acc: 0.6334\n",
      "Epoch 00020: val_acc improved from 0.58398 to 0.58772, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.8691 - acc: 0.6334 - val_loss: 0.9274 - val_acc: 0.5877\n",
      "Epoch 21/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8545 - acc: 0.6354\n",
      "Epoch 00021: val_acc did not improve from 0.58772\n",
      "7352/7352 [==============================] - 15s 2ms/sample - loss: 0.8546 - acc: 0.6357 - val_loss: 0.9164 - val_acc: 0.5870\n",
      "Epoch 22/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8426 - acc: 0.6427\n",
      "Epoch 00022: val_acc improved from 0.58772 to 0.59247, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 13s 2ms/sample - loss: 0.8425 - acc: 0.6427 - val_loss: 0.9072 - val_acc: 0.5925\n",
      "Epoch 23/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8340 - acc: 0.6379\n",
      "Epoch 00023: val_acc improved from 0.59247 to 0.59348, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 14s 2ms/sample - loss: 0.8333 - acc: 0.6381 - val_loss: 0.8980 - val_acc: 0.5935\n",
      "Epoch 24/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8231 - acc: 0.6372\n",
      "Epoch 00024: val_acc improved from 0.59348 to 0.59484, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 15s 2ms/sample - loss: 0.8226 - acc: 0.6368 - val_loss: 0.8919 - val_acc: 0.5948\n",
      "Epoch 25/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8112 - acc: 0.6449\n",
      "Epoch 00025: val_acc improved from 0.59484 to 0.59688, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 28s 4ms/sample - loss: 0.8121 - acc: 0.6446 - val_loss: 0.8844 - val_acc: 0.5969\n",
      "Epoch 26/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.8075 - acc: 0.6421\n",
      "Epoch 00026: val_acc improved from 0.59688 to 0.59925, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 0.8075 - acc: 0.6417 - val_loss: 0.8804 - val_acc: 0.5993\n",
      "Epoch 27/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.7968 - acc: 0.6494\n",
      "Epoch 00027: val_acc improved from 0.59925 to 0.60299, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 22s 3ms/sample - loss: 0.7963 - acc: 0.6503 - val_loss: 0.8736 - val_acc: 0.6030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.7918 - acc: 0.6512\n",
      "Epoch 00028: val_acc improved from 0.60299 to 0.60333, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 15s 2ms/sample - loss: 0.7915 - acc: 0.6513 - val_loss: 0.8691 - val_acc: 0.6033\n",
      "Epoch 29/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.7829 - acc: 0.6573\n",
      "Epoch 00029: val_acc improved from 0.60333 to 0.61351, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 13s 2ms/sample - loss: 0.7828 - acc: 0.6574 - val_loss: 0.8651 - val_acc: 0.6135\n",
      "Epoch 30/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.7789 - acc: 0.6497\n",
      "Epoch 00030: val_acc improved from 0.61351 to 0.61384, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 12s 2ms/sample - loss: 0.7797 - acc: 0.6489 - val_loss: 0.8602 - val_acc: 0.6138\n",
      "Epoch 31/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.7733 - acc: 0.6509\n",
      "Epoch 00031: val_acc improved from 0.61384 to 0.62029, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 12s 2ms/sample - loss: 0.7740 - acc: 0.6504 - val_loss: 0.8577 - val_acc: 0.6203\n",
      "Epoch 32/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.7670 - acc: 0.6550\n",
      "Epoch 00032: val_acc did not improve from 0.62029\n",
      "7352/7352 [==============================] - 13s 2ms/sample - loss: 0.7669 - acc: 0.6553 - val_loss: 0.8532 - val_acc: 0.6172\n",
      "Epoch 33/40\n",
      "7296/7352 [============================>.] - ETA: 0s - loss: 0.7603 - acc: 0.6550\n",
      "Epoch 00033: val_acc did not improve from 0.62029\n",
      "7352/7352 [==============================] - 15s 2ms/sample - loss: 0.7598 - acc: 0.6552 - val_loss: 0.8508 - val_acc: 0.6200\n",
      "Epoch 34/40\n",
      "6080/7352 [=======================>......] - ETA: 2s - loss: 0.7485 - acc: 0.6633"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-908152f713b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m model.fit(trainX, trainy, batch_size=64, nb_epoch=40,\n\u001b[1;32m     11\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m          callbacks = callbacks)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/mango/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/mango/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mango/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/miniconda3/envs/mango/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath = 'LSTM_Best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, nb_epoch=40,\n",
    "            verbose=1, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BI-Directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
