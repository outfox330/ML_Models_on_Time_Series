{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM models on the UCI datasets\n",
    "- LSTM Models are slow to train. The newly proposed TCNs are shown to be simpler and easier to train, along with better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        #print(data.shape)\n",
    "        loaded.append(data)\n",
    "        \n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let us create a MLP network first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
      "(7352, 1152)\n",
      "(2947, 1152)\n"
     ]
    }
   ],
   "source": [
    "# MLP with take 1-D data as an input\n",
    "\n",
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()\n",
    "\n",
    "trainX = trainX.reshape(7352,-1)\n",
    "print(trainX.shape)\n",
    "\n",
    "testX = testX.reshape(2947, -1)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 80,230\n",
      "Trainable params: 80,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MLP Network\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89006, saving model to MLP_Best.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.89006\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.89006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2481cf9bb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'MLP_Best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, epochs=100,\n",
    "            verbose=0, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 - 0s - loss: 0.9975 - accuracy: 0.8901\n",
      "MLP model, accuracy: 89.01%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filepath)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"MLP model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us do a 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 124, 64)           2944      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 61, 32)            6176      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1952)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                62496     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 71,814\n",
      "Trainable params: 71,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1-D CNN Network\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3, strides=2, activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 17:12:40.080132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-05 17:12:43.278101: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-03-05 17:12:43.355426: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 11s 41ms/step - loss: 1.0306 - accuracy: 0.5777 - val_loss: 0.4357 - val_accuracy: 0.8534\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85341, saving model to 1D_CNN_Best.hdf5\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3281 - accuracy: 0.8765 - val_loss: 0.2720 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85341 to 0.90906, saving model to 1D_CNN_Best.hdf5\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1895 - accuracy: 0.9284 - val_loss: 0.2511 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.90906 to 0.91076, saving model to 1D_CNN_Best.hdf5\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1524 - accuracy: 0.9438 - val_loss: 0.2478 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91076 to 0.91924, saving model to 1D_CNN_Best.hdf5\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1479 - accuracy: 0.9382 - val_loss: 0.2804 - val_accuracy: 0.9043\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91924\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1394 - accuracy: 0.9426 - val_loss: 0.2955 - val_accuracy: 0.9006\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91924\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1331 - accuracy: 0.9460 - val_loss: 0.2494 - val_accuracy: 0.9169\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91924\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1302 - accuracy: 0.9443 - val_loss: 0.2684 - val_accuracy: 0.9152\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91924\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1243 - accuracy: 0.9448 - val_loss: 0.2737 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.91924\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.9529 - val_loss: 0.2678 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.91924 to 0.92704, saving model to 1D_CNN_Best.hdf5\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.1144 - accuracy: 0.9484 - val_loss: 0.2719 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.92704 to 0.92806, saving model to 1D_CNN_Best.hdf5\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9520 - val_loss: 0.3069 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.92806\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1180 - accuracy: 0.9481 - val_loss: 0.2608 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.92806\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0989 - accuracy: 0.9545 - val_loss: 0.2731 - val_accuracy: 0.9203\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.92806\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0995 - accuracy: 0.9530 - val_loss: 0.3046 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.92806\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.1013 - accuracy: 0.9536 - val_loss: 0.3294 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.92806\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0914 - accuracy: 0.9584 - val_loss: 0.3487 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92806\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1047 - accuracy: 0.9485 - val_loss: 0.4162 - val_accuracy: 0.9169\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92806\n",
      "Epoch 19/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0894 - accuracy: 0.9582 - val_loss: 0.4218 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92806\n",
      "Epoch 20/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.0865 - accuracy: 0.9594 - val_loss: 0.3812 - val_accuracy: 0.9338\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.92806 to 0.93383, saving model to 1D_CNN_Best.hdf5\n",
      "Epoch 21/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9563 - val_loss: 0.4340 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.93383\n",
      "Epoch 22/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0907 - accuracy: 0.9596 - val_loss: 0.4657 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.93383\n",
      "Epoch 23/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1005 - accuracy: 0.9565 - val_loss: 0.3767 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.93383\n",
      "Epoch 24/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.0781 - accuracy: 0.9614 - val_loss: 0.4628 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.93383\n",
      "Epoch 25/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0848 - accuracy: 0.9569 - val_loss: 0.5231 - val_accuracy: 0.9087\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.93383\n",
      "Epoch 26/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0794 - accuracy: 0.9592 - val_loss: 0.5116 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.93383\n",
      "Epoch 27/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0974 - accuracy: 0.9542 - val_loss: 0.5009 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.93383\n",
      "Epoch 28/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0802 - accuracy: 0.9573 - val_loss: 0.5467 - val_accuracy: 0.9152\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.93383\n",
      "Epoch 29/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0785 - accuracy: 0.9604 - val_loss: 0.5889 - val_accuracy: 0.9067\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.93383\n",
      "Epoch 30/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0880 - accuracy: 0.9574 - val_loss: 0.4787 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.93383\n",
      "Epoch 31/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0745 - accuracy: 0.9606 - val_loss: 0.5137 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.93383\n",
      "Epoch 32/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0752 - accuracy: 0.9634 - val_loss: 0.5039 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.93383\n",
      "Epoch 33/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0722 - accuracy: 0.9607 - val_loss: 0.5795 - val_accuracy: 0.9321\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.93383\n",
      "Epoch 34/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0677 - accuracy: 0.9632 - val_loss: 0.5685 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.93383\n",
      "Epoch 35/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0694 - accuracy: 0.9616 - val_loss: 0.5522 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.93383\n",
      "Epoch 36/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0690 - accuracy: 0.9652 - val_loss: 0.6559 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.93383\n",
      "Epoch 37/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0705 - accuracy: 0.9657 - val_loss: 0.6836 - val_accuracy: 0.9094\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.93383\n",
      "Epoch 38/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.0678 - accuracy: 0.9646 - val_loss: 0.7244 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.93383\n",
      "Epoch 39/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0860 - accuracy: 0.9624 - val_loss: 0.6223 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.93383\n",
      "Epoch 40/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0720 - accuracy: 0.9614 - val_loss: 0.6543 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.93383\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0674 - accuracy: 0.9631 - val_loss: 0.7040 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.93383\n",
      "Epoch 42/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0665 - accuracy: 0.9681 - val_loss: 0.6289 - val_accuracy: 0.9121\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.93383\n",
      "Epoch 43/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0701 - accuracy: 0.9633 - val_loss: 0.6414 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.93383\n",
      "Epoch 44/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0675 - accuracy: 0.9622 - val_loss: 0.6740 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.93383\n",
      "Epoch 45/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0673 - accuracy: 0.9657 - val_loss: 0.6350 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.93383\n",
      "Epoch 46/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0742 - accuracy: 0.9652 - val_loss: 0.6615 - val_accuracy: 0.9165\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.93383\n",
      "Epoch 47/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0713 - accuracy: 0.9633 - val_loss: 0.6432 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.93383\n",
      "Epoch 48/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0590 - accuracy: 0.9690 - val_loss: 0.6834 - val_accuracy: 0.9121\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.93383\n",
      "Epoch 49/100\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.0628 - accuracy: 0.9674 - val_loss: 0.7803 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.93383\n",
      "Epoch 50/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0615 - accuracy: 0.9701 - val_loss: 0.6640 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.93383\n",
      "Epoch 51/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0713 - accuracy: 0.9623 - val_loss: 0.7702 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.93383\n",
      "Epoch 52/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0594 - accuracy: 0.9669 - val_loss: 0.7820 - val_accuracy: 0.9046\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.93383\n",
      "Epoch 53/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0708 - accuracy: 0.9671 - val_loss: 0.5292 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.93383\n",
      "Epoch 54/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 0.9659 - val_loss: 0.5951 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.93383\n",
      "Epoch 55/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0612 - accuracy: 0.9690 - val_loss: 0.6477 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.93383\n",
      "Epoch 56/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0636 - accuracy: 0.9701 - val_loss: 0.5378 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.93383\n",
      "Epoch 57/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0751 - accuracy: 0.9662 - val_loss: 0.5892 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.93383\n",
      "Epoch 58/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0590 - accuracy: 0.9697 - val_loss: 0.6161 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.93383\n",
      "Epoch 59/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0660 - accuracy: 0.9658 - val_loss: 0.6956 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.93383\n",
      "Epoch 60/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0554 - accuracy: 0.9724 - val_loss: 0.6506 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.93383\n",
      "Epoch 61/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0567 - accuracy: 0.9710 - val_loss: 0.6632 - val_accuracy: 0.9033\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.93383\n",
      "Epoch 62/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0594 - accuracy: 0.9692 - val_loss: 0.6824 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.93383\n",
      "Epoch 63/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0545 - accuracy: 0.9720 - val_loss: 0.7940 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.93383\n",
      "Epoch 64/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0626 - accuracy: 0.9713 - val_loss: 0.8056 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.93383\n",
      "Epoch 65/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0640 - accuracy: 0.9704 - val_loss: 0.7116 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.93383\n",
      "Epoch 66/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0528 - accuracy: 0.9738 - val_loss: 0.7218 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.93383\n",
      "Epoch 67/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0507 - accuracy: 0.9730 - val_loss: 0.7193 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.93383\n",
      "Epoch 68/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0601 - accuracy: 0.9691 - val_loss: 0.9581 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.93383\n",
      "Epoch 69/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0573 - accuracy: 0.9710 - val_loss: 1.0053 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.93383\n",
      "Epoch 70/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0579 - accuracy: 0.9723 - val_loss: 0.8311 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.93383\n",
      "Epoch 71/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0586 - accuracy: 0.9712 - val_loss: 0.9087 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.93383\n",
      "Epoch 72/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.0549 - accuracy: 0.9684 - val_loss: 0.9460 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.93383\n",
      "Epoch 73/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0596 - accuracy: 0.9713 - val_loss: 1.0139 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.93383\n",
      "Epoch 74/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.0582 - accuracy: 0.9710 - val_loss: 0.8507 - val_accuracy: 0.9145\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.93383\n",
      "Epoch 75/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.0519 - accuracy: 0.9752 - val_loss: 0.9498 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.93383\n",
      "Epoch 76/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0564 - accuracy: 0.9739 - val_loss: 0.8916 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.93383\n",
      "Epoch 77/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0519 - accuracy: 0.9770 - val_loss: 0.9617 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.93383\n",
      "Epoch 78/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0466 - accuracy: 0.9760 - val_loss: 0.8835 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.93383\n",
      "Epoch 79/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0491 - accuracy: 0.9762 - val_loss: 0.7876 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.93383\n",
      "Epoch 80/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0500 - accuracy: 0.9762 - val_loss: 1.0568 - val_accuracy: 0.8992\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.93383\n",
      "Epoch 81/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0561 - accuracy: 0.9775 - val_loss: 0.9327 - val_accuracy: 0.9114\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.93383\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0523 - accuracy: 0.9720 - val_loss: 0.9726 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.93383\n",
      "Epoch 83/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0484 - accuracy: 0.9748 - val_loss: 1.0054 - val_accuracy: 0.9152\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.93383\n",
      "Epoch 84/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0401 - accuracy: 0.9800 - val_loss: 1.0843 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.93383\n",
      "Epoch 85/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0458 - accuracy: 0.9782 - val_loss: 1.1424 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.93383\n",
      "Epoch 86/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0453 - accuracy: 0.9759 - val_loss: 1.1381 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.93383\n",
      "Epoch 87/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0476 - accuracy: 0.9786 - val_loss: 1.3764 - val_accuracy: 0.9125\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.93383\n",
      "Epoch 88/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0392 - accuracy: 0.9801 - val_loss: 1.3255 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.93383\n",
      "Epoch 89/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0451 - accuracy: 0.9775 - val_loss: 1.1184 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.93383\n",
      "Epoch 90/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0428 - accuracy: 0.9787 - val_loss: 1.4214 - val_accuracy: 0.8880\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.93383\n",
      "Epoch 91/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0679 - accuracy: 0.9710 - val_loss: 1.3645 - val_accuracy: 0.9016\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.93383\n",
      "Epoch 92/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0457 - accuracy: 0.9778 - val_loss: 1.2342 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.93383\n",
      "Epoch 93/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0427 - accuracy: 0.9790 - val_loss: 1.2047 - val_accuracy: 0.9043\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.93383\n",
      "Epoch 94/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0434 - accuracy: 0.9755 - val_loss: 1.2294 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.93383\n",
      "Epoch 95/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0471 - accuracy: 0.9778 - val_loss: 1.2513 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.93383\n",
      "Epoch 96/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.0666 - accuracy: 0.9744 - val_loss: 1.3132 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.93383\n",
      "Epoch 97/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0563 - accuracy: 0.9680 - val_loss: 1.3008 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.93383\n",
      "Epoch 98/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.0386 - accuracy: 0.9811 - val_loss: 1.2320 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.93383\n",
      "Epoch 99/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0393 - accuracy: 0.9789 - val_loss: 1.1804 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.93383\n",
      "Epoch 100/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0385 - accuracy: 0.9841 - val_loss: 1.1726 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.93383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f247c037d60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '1D_CNN_Best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, epochs=100,\n",
    "            verbose=1, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 - 1s - loss: 0.3812 - accuracy: 0.9338\n",
      "1D CNN model, accuracy: 93.38%\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate the model\n",
    "model.load_weights(filepath)\n",
    "\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"1D CNN model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
      "(7352, 128, 9, 1)\n",
      "(2947, 128, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = load_dataset()\n",
    "\n",
    "trainX = trainX.reshape(7352,trainX.shape[1], trainX.shape[2], 1)\n",
    "print(trainX.shape)\n",
    "\n",
    "testX = testX.reshape(2947, testX.shape[1], testX.shape[2], 1)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 5, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 2, 32)         18464     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3904)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                124960    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 145,286\n",
      "Trainable params: 145,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2-D CNN Network\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1], trainX.shape[2], 1)))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 9s 50ms/step - loss: 0.9626 - accuracy: 0.6378 - val_loss: 0.5160 - val_accuracy: 0.8042\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80421, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3470 - accuracy: 0.8668 - val_loss: 0.4378 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.80421 to 0.84866, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1897 - accuracy: 0.9318 - val_loss: 0.3707 - val_accuracy: 0.8955\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.84866 to 0.89549, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1518 - accuracy: 0.9450 - val_loss: 0.3598 - val_accuracy: 0.9050\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.89549 to 0.90499, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1224 - accuracy: 0.9517 - val_loss: 0.3871 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.90499 to 0.91177, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9534 - val_loss: 0.3937 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91177\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1211 - accuracy: 0.9545 - val_loss: 0.3360 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91177 to 0.91788, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0936 - accuracy: 0.9625 - val_loss: 0.3470 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91788 to 0.92433, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.1044 - accuracy: 0.9544 - val_loss: 0.3686 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.92433\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1129 - accuracy: 0.9545 - val_loss: 0.4967 - val_accuracy: 0.8965\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.92433\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0966 - accuracy: 0.9564 - val_loss: 0.4524 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.92433\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0928 - accuracy: 0.9535 - val_loss: 0.5383 - val_accuracy: 0.9087\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.92433\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9619 - val_loss: 0.6363 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.92433\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9622 - val_loss: 0.5403 - val_accuracy: 0.9009\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.92433\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0772 - accuracy: 0.9634 - val_loss: 0.6379 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.92433\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0782 - accuracy: 0.9658 - val_loss: 0.5932 - val_accuracy: 0.9016\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.92433\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0690 - accuracy: 0.9683 - val_loss: 0.7063 - val_accuracy: 0.8907\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92433\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0764 - accuracy: 0.9681 - val_loss: 0.6436 - val_accuracy: 0.8921\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92433\n",
      "Epoch 19/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0799 - accuracy: 0.9626 - val_loss: 0.7406 - val_accuracy: 0.9063\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92433\n",
      "Epoch 20/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 0.9712 - val_loss: 0.8627 - val_accuracy: 0.9019\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92433\n",
      "Epoch 21/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0571 - accuracy: 0.9753 - val_loss: 0.8897 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.92433\n",
      "Epoch 22/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0679 - accuracy: 0.9702 - val_loss: 1.0923 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92433\n",
      "Epoch 23/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0931 - accuracy: 0.9654 - val_loss: 0.4196 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92433\n",
      "Epoch 24/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0710 - accuracy: 0.9696 - val_loss: 0.4506 - val_accuracy: 0.9203\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.92433\n",
      "Epoch 25/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0514 - accuracy: 0.9765 - val_loss: 0.4618 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92433\n",
      "Epoch 26/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0524 - accuracy: 0.9750 - val_loss: 0.5670 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.92433\n",
      "Epoch 27/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0487 - accuracy: 0.9782 - val_loss: 0.4844 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.92433 to 0.92637, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 28/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0489 - accuracy: 0.9796 - val_loss: 0.4730 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92637\n",
      "Epoch 29/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0415 - accuracy: 0.9823 - val_loss: 0.5722 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.92637 to 0.93010, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 30/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0419 - accuracy: 0.9822 - val_loss: 0.5484 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.93010 to 0.93044, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 31/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0587 - accuracy: 0.9757 - val_loss: 0.4439 - val_accuracy: 0.9403\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.93044 to 0.94028, saving model to 2D_CNN_Best.hdf5\n",
      "Epoch 32/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0461 - accuracy: 0.9788 - val_loss: 0.6730 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.94028\n",
      "Epoch 33/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0563 - accuracy: 0.9749 - val_loss: 0.7028 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.94028\n",
      "Epoch 34/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0457 - accuracy: 0.9796 - val_loss: 0.6855 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.94028\n",
      "Epoch 35/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0475 - accuracy: 0.9795 - val_loss: 0.6664 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.94028\n",
      "Epoch 36/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0451 - accuracy: 0.9807 - val_loss: 0.6760 - val_accuracy: 0.9355\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.94028\n",
      "Epoch 37/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0449 - accuracy: 0.9813 - val_loss: 0.8623 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.94028\n",
      "Epoch 38/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0363 - accuracy: 0.9842 - val_loss: 0.7238 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.94028\n",
      "Epoch 39/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0414 - accuracy: 0.9807 - val_loss: 0.7981 - val_accuracy: 0.9328\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.94028\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0306 - accuracy: 0.9867 - val_loss: 0.8002 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.94028\n",
      "Epoch 41/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0348 - accuracy: 0.9841 - val_loss: 0.8385 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.94028\n",
      "Epoch 42/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9871 - val_loss: 0.8288 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.94028\n",
      "Epoch 43/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0369 - accuracy: 0.9849 - val_loss: 0.9019 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.94028\n",
      "Epoch 44/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0339 - accuracy: 0.9849 - val_loss: 0.7680 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.94028\n",
      "Epoch 45/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0371 - accuracy: 0.9859 - val_loss: 1.0905 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.94028\n",
      "Epoch 46/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0522 - accuracy: 0.9826 - val_loss: 0.9094 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.94028\n",
      "Epoch 47/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.8497 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.94028\n",
      "Epoch 48/100\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.0415 - accuracy: 0.9814 - val_loss: 0.8911 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.94028\n",
      "Epoch 49/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0280 - accuracy: 0.9883 - val_loss: 0.9129 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.94028\n",
      "Epoch 50/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0328 - accuracy: 0.9867 - val_loss: 0.8751 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.94028\n",
      "Epoch 51/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0254 - accuracy: 0.9899 - val_loss: 1.0499 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.94028\n",
      "Epoch 52/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 1.0416 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.94028\n",
      "Epoch 53/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0283 - accuracy: 0.9889 - val_loss: 1.0973 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.94028\n",
      "Epoch 54/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0434 - accuracy: 0.9828 - val_loss: 0.8153 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.94028\n",
      "Epoch 55/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0263 - accuracy: 0.9897 - val_loss: 1.3323 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.94028\n",
      "Epoch 56/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0275 - accuracy: 0.9897 - val_loss: 1.0630 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.94028\n",
      "Epoch 57/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 1.2229 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.94028\n",
      "Epoch 58/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0284 - accuracy: 0.9876 - val_loss: 1.2074 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.94028\n",
      "Epoch 59/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0301 - accuracy: 0.9865 - val_loss: 1.3631 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.94028\n",
      "Epoch 60/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0240 - accuracy: 0.9888 - val_loss: 0.9069 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.94028\n",
      "Epoch 61/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0552 - accuracy: 0.9842 - val_loss: 1.4307 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.94028\n",
      "Epoch 62/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9903 - val_loss: 1.6200 - val_accuracy: 0.9270\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.94028\n",
      "Epoch 63/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0199 - accuracy: 0.9906 - val_loss: 1.3924 - val_accuracy: 0.9121\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.94028\n",
      "Epoch 64/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0271 - accuracy: 0.9881 - val_loss: 1.4006 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.94028\n",
      "Epoch 65/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 1.4640 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.94028\n",
      "Epoch 66/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0205 - accuracy: 0.9922 - val_loss: 1.5892 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.94028\n",
      "Epoch 67/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0203 - accuracy: 0.9925 - val_loss: 2.1923 - val_accuracy: 0.8955\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.94028\n",
      "Epoch 68/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0299 - accuracy: 0.9867 - val_loss: 2.0305 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.94028\n",
      "Epoch 69/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0323 - accuracy: 0.9892 - val_loss: 1.9793 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.94028\n",
      "Epoch 70/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0253 - accuracy: 0.9903 - val_loss: 1.8331 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.94028\n",
      "Epoch 71/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 1.6273 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.94028\n",
      "Epoch 72/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 1.8223 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.94028\n",
      "Epoch 73/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 2.2125 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.94028\n",
      "Epoch 74/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 2.5678 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.94028\n",
      "Epoch 75/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0190 - accuracy: 0.9923 - val_loss: 2.4678 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.94028\n",
      "Epoch 76/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 2.0266 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.94028\n",
      "Epoch 77/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0371 - accuracy: 0.9874 - val_loss: 1.9463 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.94028\n",
      "Epoch 78/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 2.0084 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.94028\n",
      "Epoch 79/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 2.1878 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.94028\n",
      "Epoch 80/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0489 - accuracy: 0.9886 - val_loss: 2.6605 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.94028\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 6ms/step - loss: 0.0213 - accuracy: 0.9910 - val_loss: 2.3600 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.94028\n",
      "Epoch 82/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 1.9623 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.94028\n",
      "Epoch 83/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0479 - accuracy: 0.9862 - val_loss: 1.8041 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.94028\n",
      "Epoch 84/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0162 - accuracy: 0.9938 - val_loss: 2.0896 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.94028\n",
      "Epoch 85/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 2.2209 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.94028\n",
      "Epoch 86/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 2.1917 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.94028\n",
      "Epoch 87/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0202 - accuracy: 0.9924 - val_loss: 2.2275 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.94028\n",
      "Epoch 88/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 1.9782 - val_accuracy: 0.9321\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.94028\n",
      "Epoch 89/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0173 - accuracy: 0.9935 - val_loss: 1.9878 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.94028\n",
      "Epoch 90/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9916 - val_loss: 2.0921 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.94028\n",
      "Epoch 91/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 1.6080 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.94028\n",
      "Epoch 92/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 3.1495 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.94028\n",
      "Epoch 93/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0159 - accuracy: 0.9930 - val_loss: 2.8768 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.94028\n",
      "Epoch 94/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0281 - accuracy: 0.9931 - val_loss: 2.3642 - val_accuracy: 0.9335\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.94028\n",
      "Epoch 95/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0160 - accuracy: 0.9940 - val_loss: 2.4025 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.94028\n",
      "Epoch 96/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0164 - accuracy: 0.9941 - val_loss: 2.2887 - val_accuracy: 0.9284\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.94028\n",
      "Epoch 97/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 2.4475 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.94028\n",
      "Epoch 98/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.9952 - val_loss: 2.8576 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.94028\n",
      "Epoch 99/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 2.8982 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.94028\n",
      "Epoch 100/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 3.1258 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.94028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2484d92430>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '2D_CNN_Best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, epochs=100,\n",
    "            verbose=1, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 - 2s - loss: 0.4439 - accuracy: 0.9403\n",
      "2D CNN model, accuracy: 94.03%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filepath)\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"2D CNN model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using only ACC and GYRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        #print(data.shape)\n",
    "        loaded.append(data)\n",
    "        \n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 6) (7352, 6) (2947, 128, 6) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 124, 64)           1984      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 61, 32)            6176      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1952)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                62496     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 70,854\n",
      "Trainable params: 70,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1-D CNN Network\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=3, strides=2, activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 5s 26ms/step - loss: 1.4398 - accuracy: 0.3380 - val_loss: 0.7383 - val_accuracy: 0.6240\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62402, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.7244 - accuracy: 0.6284 - val_loss: 0.6601 - val_accuracy: 0.6960\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.62402 to 0.69596, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.6273 - accuracy: 0.6694 - val_loss: 0.7005 - val_accuracy: 0.6471\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.69596\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.6044 - accuracy: 0.6787 - val_loss: 0.6320 - val_accuracy: 0.6970\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.69596 to 0.69698, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5663 - accuracy: 0.7085 - val_loss: 0.6185 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.69698 to 0.73906, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5434 - accuracy: 0.7281 - val_loss: 0.6046 - val_accuracy: 0.7360\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73906\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.5154 - accuracy: 0.7482 - val_loss: 0.5192 - val_accuracy: 0.7631\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.73906 to 0.76315, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.4867 - accuracy: 0.7717 - val_loss: 0.5018 - val_accuracy: 0.8066\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.76315 to 0.80658, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.4634 - accuracy: 0.7886 - val_loss: 0.5140 - val_accuracy: 0.8130\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.80658 to 0.81303, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.4358 - accuracy: 0.8071 - val_loss: 0.4731 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.81303 to 0.81948, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.4007 - accuracy: 0.8356 - val_loss: 0.4839 - val_accuracy: 0.8395\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.81948 to 0.83950, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3688 - accuracy: 0.8555 - val_loss: 0.4505 - val_accuracy: 0.8442\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.83950 to 0.84425, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3525 - accuracy: 0.8591 - val_loss: 0.4399 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.84425 to 0.85714, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3182 - accuracy: 0.8668 - val_loss: 0.4404 - val_accuracy: 0.8677\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.85714 to 0.86766, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3223 - accuracy: 0.8704 - val_loss: 0.4251 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.86766 to 0.87852, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.2765 - accuracy: 0.8939 - val_loss: 0.4885 - val_accuracy: 0.8341\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.87852\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.2645 - accuracy: 0.8928 - val_loss: 0.5636 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.87852\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.2504 - accuracy: 0.9024 - val_loss: 0.3946 - val_accuracy: 0.8724\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.87852\n",
      "Epoch 19/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.2445 - accuracy: 0.9013 - val_loss: 0.5008 - val_accuracy: 0.8795\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.87852 to 0.87954, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 20/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.2431 - accuracy: 0.9049 - val_loss: 0.4225 - val_accuracy: 0.8935\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.87954 to 0.89345, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 21/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.2316 - accuracy: 0.9163 - val_loss: 0.4142 - val_accuracy: 0.8914\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.89345\n",
      "Epoch 22/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.2053 - accuracy: 0.9207 - val_loss: 0.4537 - val_accuracy: 0.8863\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.89345\n",
      "Epoch 23/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.2076 - accuracy: 0.9232 - val_loss: 0.4280 - val_accuracy: 0.8901\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.89345\n",
      "Epoch 24/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9209 - val_loss: 0.4310 - val_accuracy: 0.8941\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.89345 to 0.89413, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 25/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1788 - accuracy: 0.9324 - val_loss: 0.5829 - val_accuracy: 0.8619\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.89413\n",
      "Epoch 26/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9205 - val_loss: 0.4286 - val_accuracy: 0.8992\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.89413 to 0.89922, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 27/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1819 - accuracy: 0.9331 - val_loss: 0.5671 - val_accuracy: 0.8819\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.89922\n",
      "Epoch 28/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1812 - accuracy: 0.9314 - val_loss: 0.4955 - val_accuracy: 0.8856\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.89922\n",
      "Epoch 29/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1708 - accuracy: 0.9423 - val_loss: 0.4591 - val_accuracy: 0.9013\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.89922 to 0.90126, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 30/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1702 - accuracy: 0.9397 - val_loss: 0.4729 - val_accuracy: 0.8931\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.90126\n",
      "Epoch 31/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1628 - accuracy: 0.9353 - val_loss: 0.4431 - val_accuracy: 0.8924\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90126\n",
      "Epoch 32/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1613 - accuracy: 0.9380 - val_loss: 0.5102 - val_accuracy: 0.8918\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.90126\n",
      "Epoch 33/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1630 - accuracy: 0.9372 - val_loss: 0.4229 - val_accuracy: 0.9050\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.90126 to 0.90499, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 34/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1444 - accuracy: 0.9493 - val_loss: 0.5185 - val_accuracy: 0.8890\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.90499\n",
      "Epoch 35/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1502 - accuracy: 0.9424 - val_loss: 0.4301 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.90499 to 0.90702, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 36/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1398 - accuracy: 0.9474 - val_loss: 0.5122 - val_accuracy: 0.8884\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.90702\n",
      "Epoch 37/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1468 - accuracy: 0.9468 - val_loss: 0.5183 - val_accuracy: 0.8982\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.90702\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1396 - accuracy: 0.9483 - val_loss: 0.5155 - val_accuracy: 0.9009\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.90702\n",
      "Epoch 39/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1454 - accuracy: 0.9468 - val_loss: 0.5818 - val_accuracy: 0.8972\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.90702\n",
      "Epoch 40/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1388 - accuracy: 0.9489 - val_loss: 0.5532 - val_accuracy: 0.8965\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.90702\n",
      "Epoch 41/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1370 - accuracy: 0.9477 - val_loss: 0.5410 - val_accuracy: 0.8897\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.90702\n",
      "Epoch 42/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1233 - accuracy: 0.9568 - val_loss: 0.5315 - val_accuracy: 0.8921\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.90702\n",
      "Epoch 43/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1226 - accuracy: 0.9535 - val_loss: 0.4588 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.90702 to 0.90804, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 44/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1280 - accuracy: 0.9520 - val_loss: 0.5263 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.90804\n",
      "Epoch 45/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1344 - accuracy: 0.9510 - val_loss: 0.4913 - val_accuracy: 0.9094\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.90804 to 0.90940, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 46/100\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.1222 - accuracy: 0.9562 - val_loss: 0.4345 - val_accuracy: 0.9145\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.90940 to 0.91449, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 47/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1226 - accuracy: 0.9548 - val_loss: 0.5219 - val_accuracy: 0.9074\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.91449\n",
      "Epoch 48/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1147 - accuracy: 0.9551 - val_loss: 0.5245 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.91449\n",
      "Epoch 49/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1151 - accuracy: 0.9567 - val_loss: 0.5708 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.91449\n",
      "Epoch 50/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1008 - accuracy: 0.9612 - val_loss: 0.6239 - val_accuracy: 0.8941\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.91449\n",
      "Epoch 51/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1099 - accuracy: 0.9602 - val_loss: 0.5379 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.91449\n",
      "Epoch 52/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9592 - val_loss: 0.6018 - val_accuracy: 0.9026\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.91449\n",
      "Epoch 53/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1056 - accuracy: 0.9639 - val_loss: 0.6596 - val_accuracy: 0.9019\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.91449\n",
      "Epoch 54/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1003 - accuracy: 0.9642 - val_loss: 0.5962 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.91449\n",
      "Epoch 55/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1045 - accuracy: 0.9610 - val_loss: 0.6011 - val_accuracy: 0.8948\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.91449\n",
      "Epoch 56/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0951 - accuracy: 0.9653 - val_loss: 0.5878 - val_accuracy: 0.9043\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.91449\n",
      "Epoch 57/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1034 - accuracy: 0.9620 - val_loss: 0.5637 - val_accuracy: 0.9057\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.91449\n",
      "Epoch 58/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0998 - accuracy: 0.9671 - val_loss: 0.5475 - val_accuracy: 0.9053\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.91449\n",
      "Epoch 59/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0816 - accuracy: 0.9695 - val_loss: 0.6258 - val_accuracy: 0.8897\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.91449\n",
      "Epoch 60/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0972 - accuracy: 0.9658 - val_loss: 0.7399 - val_accuracy: 0.9036\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.91449\n",
      "Epoch 61/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0926 - accuracy: 0.9662 - val_loss: 0.5695 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.91449\n",
      "Epoch 62/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9702 - val_loss: 0.6142 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.91449\n",
      "Epoch 63/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0953 - accuracy: 0.9645 - val_loss: 0.8375 - val_accuracy: 0.8968\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.91449\n",
      "Epoch 64/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0837 - accuracy: 0.9684 - val_loss: 0.6714 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.91449\n",
      "Epoch 65/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.1036 - accuracy: 0.9662 - val_loss: 0.5759 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.91449\n",
      "Epoch 66/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0854 - accuracy: 0.9685 - val_loss: 0.6537 - val_accuracy: 0.9125\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.91449\n",
      "Epoch 67/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0747 - accuracy: 0.9724 - val_loss: 0.6668 - val_accuracy: 0.9053\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.91449\n",
      "Epoch 68/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0771 - accuracy: 0.9725 - val_loss: 0.6666 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.91449\n",
      "Epoch 69/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9751 - val_loss: 0.7069 - val_accuracy: 0.9074\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.91449\n",
      "Epoch 70/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0677 - accuracy: 0.9756 - val_loss: 0.7139 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.91449\n",
      "Epoch 71/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0790 - accuracy: 0.9720 - val_loss: 0.6848 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.91449\n",
      "Epoch 72/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0703 - accuracy: 0.9774 - val_loss: 0.7687 - val_accuracy: 0.8880\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.91449\n",
      "Epoch 73/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0892 - accuracy: 0.9686 - val_loss: 0.7777 - val_accuracy: 0.9016\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.91449\n",
      "Epoch 74/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0712 - accuracy: 0.9760 - val_loss: 0.6907 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.91449\n",
      "Epoch 75/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0590 - accuracy: 0.9776 - val_loss: 0.7542 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.91449\n",
      "Epoch 76/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0683 - accuracy: 0.9764 - val_loss: 0.7493 - val_accuracy: 0.9023\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.91449\n",
      "Epoch 77/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 0.9772 - val_loss: 0.7337 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.91449\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0651 - accuracy: 0.9775 - val_loss: 0.8902 - val_accuracy: 0.9036\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.91449\n",
      "Epoch 79/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1050 - accuracy: 0.9678 - val_loss: 0.6354 - val_accuracy: 0.9074\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.91449\n",
      "Epoch 80/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0632 - accuracy: 0.9765 - val_loss: 0.6272 - val_accuracy: 0.9121\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.91449\n",
      "Epoch 81/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0576 - accuracy: 0.9790 - val_loss: 0.6758 - val_accuracy: 0.9121\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.91449\n",
      "Epoch 82/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0584 - accuracy: 0.9808 - val_loss: 0.6811 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.91449\n",
      "Epoch 83/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0576 - accuracy: 0.9793 - val_loss: 0.7421 - val_accuracy: 0.9145\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.91449\n",
      "Epoch 84/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0573 - accuracy: 0.9842 - val_loss: 0.6892 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.91449\n",
      "Epoch 85/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0585 - accuracy: 0.9792 - val_loss: 0.8566 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.91449\n",
      "Epoch 86/100\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 0.7456 - val_accuracy: 0.9026\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.91449\n",
      "Epoch 87/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0558 - accuracy: 0.9784 - val_loss: 0.7788 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.91449\n",
      "Epoch 88/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.0698 - accuracy: 0.9772 - val_loss: 0.6772 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.91449\n",
      "Epoch 89/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0604 - accuracy: 0.9782 - val_loss: 0.6831 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.91449\n",
      "Epoch 90/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0417 - accuracy: 0.9858 - val_loss: 0.7579 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.91449\n",
      "Epoch 91/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0507 - accuracy: 0.9810 - val_loss: 0.7423 - val_accuracy: 0.9053\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.91449\n",
      "Epoch 92/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0521 - accuracy: 0.9809 - val_loss: 0.8239 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.91449\n",
      "Epoch 93/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0532 - accuracy: 0.9797 - val_loss: 0.7504 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00093: val_accuracy improved from 0.91449 to 0.91619, saving model to 1D_CNN_Best_2.hdf5\n",
      "Epoch 94/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0472 - accuracy: 0.9829 - val_loss: 0.7503 - val_accuracy: 0.9094\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.91619\n",
      "Epoch 95/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0454 - accuracy: 0.9836 - val_loss: 0.7099 - val_accuracy: 0.9074\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.91619\n",
      "Epoch 96/100\n",
      "115/115 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9843 - val_loss: 0.7485 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.91619\n",
      "Epoch 97/100\n",
      "115/115 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9782 - val_loss: 0.9049 - val_accuracy: 0.8999\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.91619\n",
      "Epoch 98/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.1033 - accuracy: 0.9715 - val_loss: 0.7881 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.91619\n",
      "Epoch 99/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0442 - accuracy: 0.9850 - val_loss: 0.7925 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.91619\n",
      "Epoch 100/100\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.0475 - accuracy: 0.9811 - val_loss: 0.7871 - val_accuracy: 0.9063\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.91619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f24857a3430>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '1D_CNN_Best_2.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, epochs=100,\n",
    "            verbose=1, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 - 1s - loss: 0.7504 - accuracy: 0.9162\n",
      "1D CNN model, accuracy: 91.62%\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate the model\n",
    "model.load_weights(filepath)\n",
    "\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"1D CNN model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        #print(data.shape)\n",
    "        loaded.append(data)\n",
    "        \n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'datasets/UCI-HAR-Dataset/')\n",
    "    \n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 17:27:42.902392: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-05 17:27:42.902975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.683GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-05 17:27:42.903985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.683GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-05 17:27:42.904070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-05 17:27:42.904119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-05 17:27:42.904152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-05 17:27:42.904179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-05 17:27:42.904227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-05 17:27:42.904274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-05 17:27:42.904309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-05 17:27:42.904337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-05 17:27:42.906754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-03-05 17:27:42.906861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-05 17:27:42.906878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-03-05 17:27:42.906884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2022-03-05 17:27:42.906891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2022-03-05 17:27:42.908827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9516 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-03-05 17:27:42.909846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10269 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 16)                1664      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 2,406\n",
      "Trainable params: 2,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Network Default input: [batch, timesteps, feature]\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(tf.keras.layers.LSTM(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 8.0648 - acc: 0.4316\n",
      "Epoch 00001: val_acc improved from -inf to 0.50458, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 17s 2ms/sample - loss: 8.0648 - acc: 0.4316 - val_loss: 2.0300 - val_acc: 0.5046\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 1.3778 - acc: 0.5362\n",
      "Epoch 00002: val_acc improved from 0.50458 to 0.51612, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 1.3778 - acc: 0.5362 - val_loss: 1.5109 - val_acc: 0.5161\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 1.2239 - acc: 0.5556\n",
      "Epoch 00003: val_acc improved from 0.51612 to 0.53410, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 1.2239 - acc: 0.5556 - val_loss: 2.0348 - val_acc: 0.5341\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 1.0767 - acc: 0.5834\n",
      "Epoch 00004: val_acc improved from 0.53410 to 0.55887, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 1.0767 - acc: 0.5834 - val_loss: 2.1777 - val_acc: 0.5589\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 1.0004 - acc: 0.5933\n",
      "Epoch 00005: val_acc improved from 0.55887 to 0.57211, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 1.0004 - acc: 0.5933 - val_loss: 1.6461 - val_acc: 0.5721\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.9484 - acc: 0.6106\n",
      "Epoch 00006: val_acc improved from 0.57211 to 0.57346, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.9484 - acc: 0.6106 - val_loss: 1.4673 - val_acc: 0.5735\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.9055 - acc: 0.6185\n",
      "Epoch 00007: val_acc did not improve from 0.57346\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.9055 - acc: 0.6185 - val_loss: 1.4542 - val_acc: 0.5735\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.8729 - acc: 0.6336\n",
      "Epoch 00008: val_acc improved from 0.57346 to 0.57957, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.8729 - acc: 0.6336 - val_loss: 1.3511 - val_acc: 0.5796\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.8424 - acc: 0.6419\n",
      "Epoch 00009: val_acc improved from 0.57957 to 0.58704, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.8424 - acc: 0.6419 - val_loss: 1.2429 - val_acc: 0.5870\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.8168 - acc: 0.6492\n",
      "Epoch 00010: val_acc improved from 0.58704 to 0.59756, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.8168 - acc: 0.6492 - val_loss: 1.1140 - val_acc: 0.5976\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7925 - acc: 0.6563\n",
      "Epoch 00011: val_acc improved from 0.59756 to 0.59891, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.7925 - acc: 0.6563 - val_loss: 1.4072 - val_acc: 0.5989\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7876 - acc: 0.6642\n",
      "Epoch 00012: val_acc improved from 0.59891 to 0.60299, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.7876 - acc: 0.6642 - val_loss: 1.2326 - val_acc: 0.6030\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7670 - acc: 0.6725\n",
      "Epoch 00013: val_acc improved from 0.60299 to 0.60875, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.7670 - acc: 0.6725 - val_loss: 1.4276 - val_acc: 0.6088\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7530 - acc: 0.6708\n",
      "Epoch 00014: val_acc improved from 0.60875 to 0.62335, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.7530 - acc: 0.6708 - val_loss: 1.4924 - val_acc: 0.6233\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7349 - acc: 0.6816\n",
      "Epoch 00015: val_acc improved from 0.62335 to 0.63353, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.7349 - acc: 0.6816 - val_loss: 1.8294 - val_acc: 0.6335\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 53042630.2127 - acc: 0.6846\n",
      "Epoch 00016: val_acc did not improve from 0.63353\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 53042630.2127 - acc: 0.6846 - val_loss: 1.0127 - val_acc: 0.5579\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.8578 - acc: 0.6295\n",
      "Epoch 00017: val_acc did not improve from 0.63353\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.8578 - acc: 0.6295 - val_loss: 0.9240 - val_acc: 0.6281\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7925 - acc: 0.6681\n",
      "Epoch 00018: val_acc did not improve from 0.63353\n",
      "7352/7352 [==============================] - 16s 2ms/sample - loss: 0.7925 - acc: 0.6681 - val_loss: 0.9119 - val_acc: 0.6254\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7751 - acc: 0.6725\n",
      "Epoch 00019: val_acc improved from 0.63353 to 0.63760, saving model to LSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 17s 2ms/sample - loss: 0.7751 - acc: 0.6725 - val_loss: 0.8975 - val_acc: 0.6376\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7650 - acc: 0.6746\n",
      "Epoch 00020: val_acc did not improve from 0.63760\n",
      "7352/7352 [==============================] - 17s 2ms/sample - loss: 0.7650 - acc: 0.6746 - val_loss: 0.8913 - val_acc: 0.6332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2470601f70>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'LSTM_Best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, epochs=20,\n",
    "            verbose=1, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model, accuracy: 63.76%\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate the model\n",
    "model.load_weights(filepath)\n",
    "\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"LSTM model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BI-Directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 17:34:25.290234: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-05 17:34:25.291441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.683GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-05 17:34:25.292855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.683GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-05 17:34:25.292912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-05 17:34:25.292942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-05 17:34:25.292963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-05 17:34:25.292981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-05 17:34:25.293000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-05 17:34:25.293020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-05 17:34:25.293039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-05 17:34:25.293059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-05 17:34:25.295801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-03-05 17:34:25.295856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-05 17:34:25.295866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-03-05 17:34:25.295871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2022-03-05 17:34:25.295876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2022-03-05 17:34:25.297701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9516 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-03-05 17:34:25.298599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10269 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 32)                3328      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 4,582\n",
      "Trainable params: 4,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Network Default input: [batch, timesteps, feature]\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, activation='relu')))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(trainy.shape[1], activation='softmax'))\n",
    "#model.output_shape\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 1.9268 - acc: 0.4606\n",
      "Epoch 00001: val_acc improved from -inf to 0.55989, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 32s 4ms/sample - loss: 1.9268 - acc: 0.4606 - val_loss: 1.8444 - val_acc: 0.5599\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 1.2398 - acc: 0.5958\n",
      "Epoch 00002: val_acc did not improve from 0.55989\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 1.2398 - acc: 0.5958 - val_loss: 1.2163 - val_acc: 0.5579\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 1.0919 - acc: 0.6224\n",
      "Epoch 00003: val_acc improved from 0.55989 to 0.59518, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 1.0919 - acc: 0.6224 - val_loss: 1.0664 - val_acc: 0.5952\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.9609 - acc: 0.6394\n",
      "Epoch 00004: val_acc improved from 0.59518 to 0.61724, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 0.9609 - acc: 0.6394 - val_loss: 0.9690 - val_acc: 0.6172\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.8681 - acc: 0.6617\n",
      "Epoch 00005: val_acc improved from 0.61724 to 0.63081, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 0.8681 - acc: 0.6617 - val_loss: 0.9008 - val_acc: 0.6308\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 215575.7370 - acc: 0.6666\n",
      "Epoch 00006: val_acc did not improve from 0.63081\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 215575.7370 - acc: 0.6666 - val_loss: 29.9223 - val_acc: 0.6223\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 35.7377 - acc: 0.6650\n",
      "Epoch 00007: val_acc improved from 0.63081 to 0.63624, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 35.7377 - acc: 0.6650 - val_loss: 0.8648 - val_acc: 0.6362\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7645 - acc: 0.6824\n",
      "Epoch 00008: val_acc improved from 0.63624 to 0.65083, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 30s 4ms/sample - loss: 0.7645 - acc: 0.6824 - val_loss: 0.8377 - val_acc: 0.6508\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7407 - acc: 0.6891\n",
      "Epoch 00009: val_acc did not improve from 0.65083\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 0.7407 - acc: 0.6891 - val_loss: 0.8225 - val_acc: 0.6478\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7210 - acc: 0.6948\n",
      "Epoch 00010: val_acc improved from 0.65083 to 0.65490, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 30s 4ms/sample - loss: 0.7210 - acc: 0.6948 - val_loss: 0.8090 - val_acc: 0.6549\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.7075 - acc: 0.6961\n",
      "Epoch 00011: val_acc did not improve from 0.65490\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 0.7075 - acc: 0.6961 - val_loss: 0.8001 - val_acc: 0.6535\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.6886 - acc: 0.7078\n",
      "Epoch 00012: val_acc improved from 0.65490 to 0.66135, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 32s 4ms/sample - loss: 0.6886 - acc: 0.7078 - val_loss: 0.7932 - val_acc: 0.6614\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.6822 - acc: 0.7103\n",
      "Epoch 00013: val_acc did not improve from 0.66135\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 0.6822 - acc: 0.7103 - val_loss: 0.7884 - val_acc: 0.6593\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.6711 - acc: 0.7050\n",
      "Epoch 00014: val_acc improved from 0.66135 to 0.66542, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 30s 4ms/sample - loss: 0.6711 - acc: 0.7050 - val_loss: 0.7835 - val_acc: 0.6654\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.6642 - acc: 0.7062\n",
      "Epoch 00015: val_acc improved from 0.66542 to 0.66949, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 0.6642 - acc: 0.7062 - val_loss: 0.7791 - val_acc: 0.6695\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.6602 - acc: 0.7091\n",
      "Epoch 00016: val_acc did not improve from 0.66949\n",
      "7352/7352 [==============================] - 32s 4ms/sample - loss: 0.6602 - acc: 0.7091 - val_loss: 0.7738 - val_acc: 0.6685\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.6521 - acc: 0.7123\n",
      "Epoch 00017: val_acc did not improve from 0.66949\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 0.6521 - acc: 0.7123 - val_loss: 0.7719 - val_acc: 0.6681\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.6492 - acc: 0.7122\n",
      "Epoch 00018: val_acc did not improve from 0.66949\n",
      "7352/7352 [==============================] - 31s 4ms/sample - loss: 0.6492 - acc: 0.7122 - val_loss: 0.7677 - val_acc: 0.6688\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.6473 - acc: 0.7106\n",
      "Epoch 00019: val_acc did not improve from 0.66949\n",
      "7352/7352 [==============================] - 30s 4ms/sample - loss: 0.6473 - acc: 0.7106 - val_loss: 0.7658 - val_acc: 0.6675\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.6365 - acc: 0.7197\n",
      "Epoch 00020: val_acc improved from 0.66949 to 0.66983, saving model to BiLSTM_Best.hdf5\n",
      "7352/7352 [==============================] - 30s 4ms/sample - loss: 0.6365 - acc: 0.7197 - val_loss: 0.7632 - val_acc: 0.6698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f24705c3340>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'BiLSTM_Best.hdf5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "model.fit(trainX, trainy, batch_size=64, epochs=20,\n",
    "            verbose=1, validation_data=(testX, testy),\n",
    "         callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model, accuracy: 66.98%\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate the model\n",
    "model.load_weights(filepath)\n",
    "\n",
    "loss, acc = model.evaluate(testX, testy, verbose=2)\n",
    "print(\"LSTM model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
